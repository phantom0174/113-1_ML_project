{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Paths\n",
    "image_folder_path = \"LaTex_data/generated_png_images\"\n",
    "mapping_path = \"image_formula_mapping.json\"\n",
    "label_to_index_path = \"LaTex_data/230k.json\"\n",
    "\n",
    "folders = [\"split_1\", \"split_2\", \"split_3\", \"split_4\", \"split_5\", \n",
    "\t\t   \"split_6\", \"split_7\", \"split_8\", \"split_9\", \"split_10\"]\n",
    "\n",
    "with open(mapping_path, 'r') as f:\n",
    "\timage_formula_mapping = json.load(f)\n",
    "keys = list(image_formula_mapping.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "# print(len(os.listdir('LaTex_data/split_1')))\n",
    "# print(image_formula_mapping['0002475406d9932.png'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaTeXDataset(Dataset):\n",
    "    def __init__(self, image_folder, mapping_file, label_to_index_file, transform=None, max_images=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load mappings and label-to-index dictionary\n",
    "        with open(mapping_file, 'r') as f:\n",
    "            self.image_formula_mapping = json.load(f)\n",
    "        with open(label_to_index_file, 'r') as f:\n",
    "            self.label_to_index = json.load(f)\n",
    "\n",
    "        # Apply the image count limit if specified\n",
    "        # if max_images:\n",
    "        #     self.image_formula_mapping = dict(list(self.image_formula_mapping.items())[:max_images])\n",
    "\n",
    "        self.index_to_label = {v: k for k, v in self.label_to_index.items()}\n",
    "        self.vocab_size = len(self.label_to_index)\n",
    "        self.formulas = list(self.image_formula_mapping.values())\n",
    "        self.image_files = [f for f in os.listdir(image_folder) ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_files[idx]\n",
    "        formula = self.image_formula_mapping[str(image_name)]\n",
    "\n",
    "        # Load image\n",
    "        image_path = os.path.join(self.image_folder, image_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Tokenize the formula into indices\n",
    "        formula_tokens = '<S> ' + formula + ' <E>'\n",
    "        formula_tokens = formula.split()  # Splitting the formula string by whitespace\n",
    "        \n",
    "        formula_indices = []\n",
    "        for token in formula_tokens:\n",
    "            # Map each token to its index; if not found, use a default index (e.g., 0)\n",
    "            index = self.label_to_index.get(token, 0)  # Assuming 0 is for unknown tokens\n",
    "            formula_indices.append(int(index))\n",
    "        \n",
    "        # Convert the list of indices to a 1D tensor\n",
    "        return image, torch.tensor(formula_indices, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder / Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EncoderCNN, self).__init__()\n",
    "\t\tconv_tiny = models.convnext_tiny(pretrained=True)\n",
    "\n",
    "\t\tunlock_section = 'features.4'\n",
    "\t\tfor name, param in conv_tiny.named_parameters():\n",
    "\t\t\tif name.startswith(unlock_section):\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t\tparam.requires_grad = False\n",
    "\n",
    "\t\t# Remove the final classification layer\n",
    "\t\tself.conv_tiny = nn.Sequential(*list(conv_tiny.children())[:-1])\n",
    "\t\t\n",
    "\t\t# connect directly to embed part\n",
    "\t\t# Add a fully connected layer to match the desired feature_dim\n",
    "\t\t# self.fc = nn.Linear(efficientnet.classifier[1].in_features, feature_dim)\n",
    "\n",
    "\tdef forward(self, images):\n",
    "\t\t# Shape: [batch_size, feature_dim, 1, 1] = torch.Size([32, 768, 1, 1])\n",
    "\t\tfeatures = self.conv_tiny(images)\n",
    "\n",
    "\t\tfeatures = features.view(features.size(0), -1)  # Flatten to [batch_size, feature_dim]\n",
    "\t\t# features = self.fc(features)\n",
    "\t\treturn features\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "\tdef __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "\t\tsuper(DecoderRNN, self).__init__()\n",
    "\t\tself.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\t\tself.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\t\tself.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "\tdef forward(self, features, formulas):\n",
    "\t\t# Embed the input formula tokens\n",
    "\t\tembeddings = self.embedding(formulas)\n",
    "\n",
    "\t\t# Concatenate features and embeddings along the sequence dimension\n",
    "\t\tembeddings = torch.cat((features.unsqueeze(1), embeddings), dim=1)\n",
    "\t\t\n",
    "\t\t# Pass through GRU and then through the final linear layer\n",
    "\t\tgru_out, _ = self.gru(embeddings)\n",
    "\t\toutputs = self.fc(gru_out)\n",
    "\t\treturn outputs\n",
    "\n",
    "class ImageToLaTeXModel(nn.Module):\n",
    "\tdef __init__(self, encoder, decoder):\n",
    "\t\tsuper(ImageToLaTeXModel, self).__init__()\n",
    "\t\tself.encoder = encoder\n",
    "\t\tself.decoder = decoder\n",
    "\n",
    "\tdef forward(self, images, formulas):\n",
    "\t\t# Encode the images\n",
    "\t\tfeatures = self.encoder(images)  # Shape: [batch_size, feature_dim]\n",
    "\t\t\n",
    "\t\t# Decode to generate the LaTeX expression\n",
    "\t\toutputs = self.decoder(features, formulas[:, :-1])  # Skip the end token\n",
    "\t\treturn outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Separate images and formulas from the batch\n",
    "    images, formulas = zip(*batch)\n",
    "\n",
    "    # Stack images (assumes images are already the same size after transforms)\n",
    "    images = torch.stack(images)\n",
    "\n",
    "    # Pad formulas to the length of the longest formula in the batch\n",
    "    formulas = pad_sequence(formulas, batch_first=True, padding_value=2)  \n",
    "\n",
    "    return images.to(device), formulas.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save / Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming 'model' is your model and 'optimizer' is your optimizer\n",
    "def save_model(model, optimizer, epoch, loss, filename='model.pth'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, filename)\n",
    "\n",
    "def load_model(model, optimizer, filename='model.pth'):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15084\\1902565204.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('model_checkpoint.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from folder 1, epoch 0, with loss 1.0686\n",
      "Training on folder: split_1\n",
      "Folder [1/10], Epoch [1/5], Step [0/733], Loss: 0.9892\n",
      "Folder [1/10], Epoch [1/5], Step [100/733], Loss: 0.5882\n",
      "Folder [1/10], Epoch [1/5], Step [200/733], Loss: 1.1851\n",
      "Folder [1/10], Epoch [1/5], Step [300/733], Loss: 1.1410\n",
      "Folder [1/10], Epoch [1/5], Step [400/733], Loss: 0.8273\n",
      "Folder [1/10], Epoch [1/5], Step [500/733], Loss: 1.0690\n",
      "Folder [1/10], Epoch [1/5], Step [600/733], Loss: 0.8181\n",
      "Folder [1/10], Epoch [1/5], Step [700/733], Loss: 0.4615\n",
      "Folder [1/10], Epoch [2/5], Step [0/733], Loss: 0.8759\n",
      "Folder [1/10], Epoch [2/5], Step [100/733], Loss: 0.6576\n",
      "Folder [1/10], Epoch [2/5], Step [200/733], Loss: 0.6862\n",
      "Folder [1/10], Epoch [2/5], Step [300/733], Loss: 0.7525\n",
      "Folder [1/10], Epoch [2/5], Step [400/733], Loss: 0.6072\n",
      "Folder [1/10], Epoch [2/5], Step [500/733], Loss: 0.4458\n",
      "Folder [1/10], Epoch [2/5], Step [600/733], Loss: 0.7897\n",
      "Folder [1/10], Epoch [2/5], Step [700/733], Loss: 1.0050\n",
      "Folder [1/10], Epoch [3/5], Step [0/733], Loss: 0.9760\n",
      "Folder [1/10], Epoch [3/5], Step [100/733], Loss: 0.5611\n",
      "Folder [1/10], Epoch [3/5], Step [200/733], Loss: 0.8802\n",
      "Folder [1/10], Epoch [3/5], Step [300/733], Loss: 1.2965\n",
      "Folder [1/10], Epoch [3/5], Step [400/733], Loss: 0.6258\n",
      "Folder [1/10], Epoch [3/5], Step [500/733], Loss: 0.7122\n",
      "Folder [1/10], Epoch [3/5], Step [600/733], Loss: 0.7020\n",
      "Folder [1/10], Epoch [3/5], Step [700/733], Loss: 1.2895\n",
      "Folder [1/10], Epoch [4/5], Step [0/733], Loss: 0.5405\n",
      "Folder [1/10], Epoch [4/5], Step [100/733], Loss: 0.8156\n",
      "Folder [1/10], Epoch [4/5], Step [200/733], Loss: 1.0161\n",
      "Folder [1/10], Epoch [4/5], Step [300/733], Loss: 0.5938\n",
      "Folder [1/10], Epoch [4/5], Step [400/733], Loss: 0.7195\n",
      "Folder [1/10], Epoch [4/5], Step [500/733], Loss: 0.9256\n",
      "Folder [1/10], Epoch [4/5], Step [600/733], Loss: 0.4615\n",
      "Folder [1/10], Epoch [4/5], Step [700/733], Loss: 0.8452\n",
      "Folder [1/10], Epoch [5/5], Step [0/733], Loss: 0.8308\n",
      "Folder [1/10], Epoch [5/5], Step [100/733], Loss: 0.7225\n",
      "Folder [1/10], Epoch [5/5], Step [200/733], Loss: 0.4366\n",
      "Folder [1/10], Epoch [5/5], Step [300/733], Loss: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EMBED_SIZE = 768 # direct output dim from cv_tiny\n",
    "\n",
    "hidden_size = 1024\n",
    "num_epochs = 5\n",
    "learning_rate = 0.003\n",
    "batch_size = 32\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.Resize((224, 224)), # input dim of conv_next_tiny\n",
    "\ttransforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset and dataloader\n",
    "\n",
    "\n",
    "dataset = LaTeXDataset(\"LaTex_data/split_1\" , mapping_path, label_to_index_path, transform)\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "encoder = EncoderCNN().to(device)\n",
    "decoder = DecoderRNN(EMBED_SIZE, hidden_size, dataset.vocab_size).to(device)\n",
    "model = ImageToLaTeXModel(encoder, decoder).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=1)  # 0 is assumed as <PAD> token\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "start_epoch = 0\n",
    "\n",
    "# Function to save model state\n",
    "def save_training_state(model, optimizer, epoch, folder_idx, loss):\n",
    "\tstate = {\n",
    "\t\t'model_state_dict': model.state_dict(),\n",
    "\t\t'optimizer_state_dict': optimizer.state_dict(),\n",
    "\t\t'epoch': epoch,\n",
    "\t\t'folder_idx': folder_idx,\n",
    "\t\t'loss': loss\n",
    "\t}\n",
    "\ttorch.save(state, 'model_checkpoint.pth')\n",
    "\n",
    "# Function to load model state\n",
    "def load_training_state(model, optimizer):\n",
    "\tcheckpoint = torch.load('model_checkpoint.pth')\n",
    "\tmodel.load_state_dict(checkpoint['model_state_dict'])\n",
    "\toptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\treturn checkpoint['epoch'], checkpoint['folder_idx'], checkpoint['loss']\n",
    "\n",
    "# Try to resume from a checkpoint\n",
    "try:\n",
    "\tstart_epoch, start_folder_idx, last_loss = load_training_state(model, optimizer)\n",
    "\tprint(f\"Resuming training from folder {start_folder_idx+1}, epoch {start_epoch}, with loss {last_loss:.4f}\")\n",
    "except FileNotFoundError:\n",
    "\tprint(\"No saved model found, starting fresh.\")\n",
    "\tstart_epoch = 0\n",
    "\tstart_folder_idx = 0\n",
    "\n",
    "# Training loop\n",
    "for i in range(6):\n",
    "\tfor folder_idx in range(start_folder_idx, len(folders)):\n",
    "\t\tprint(f\"Training on folder: {folders[folder_idx]}\")\n",
    "\t\tdataset = LaTeXDataset(\"LaTex_data/\" + folders[folder_idx], mapping_path, label_to_index_path, transform)\n",
    "\t\tdataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\t\tfor epoch in range(start_epoch, num_epochs):\n",
    "\t\t\tfor i, data in enumerate(dataloader):\n",
    "\t\t\t\timages, formulas = data\n",
    "\t\t\t\ttargets = formulas[:, 1:]\n",
    "\n",
    "\t\t\t\toutputs = model(images, formulas[:, :-1])\n",
    "\t\t\t\tloss = criterion(outputs.view(-1, dataset.vocab_size), targets.contiguous().view(-1))\n",
    "\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t\tif i % 100 == 0:\n",
    "\t\t\t\t\tprint(f\"Folder [{folder_idx+1}/{len(folders)}], Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\t\t\t\t# Save model periodically and at the end of each folder\n",
    "\t\t\t\tif i % 200 == 0 or (i == len(dataloader) - 1):\n",
    "\t\t\t\t\tsave_training_state(model, optimizer, epoch, folder_idx, loss.item())\n",
    "\t\t\t\n",
    "\t\t\t# Reset start_epoch for next folder\n",
    "\t\t\tstart_epoch = 0\n",
    "\t\tstart_folder_idx = 0\n",
    "\t\tstart_epoch = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Formula: _ { a } \\left( z \\right) = \\int _ { 0 } ^ { \\infty } \\mathrm { d } t \\, \\mathrm { c o s h } \\left( a \\, t \\right) \\mathrm { e } ^ { - z \\, \\mathrm { c o s h } \\left( t \\right) } ,\n",
      "Predicted Formula: { \\mu } = { _ { { { { i } ^ { \\infty } d { T } a { { \\, a } } y } } y ^ { \\, \\, G o f i } } { \\, a o } s } } y ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: [ A ] = { \\frac { k } { 4 \\pi } } \\int _ { \\Sigma } \\mathrm { T r } \\left[ A \\wedge d A + \\frac { 2 } { 3 } A \\wedge A \\wedge A \\right]\n",
      "Predicted Formula: { ] { \\int [ S 1 } { 2 } } \\int \\int 2 { 0 } { { d r } [ \\wedge { A \\wedge { \\wedge r } } 4 } } 2 { ^ { } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { Q } = \\int d ^ { 2 } x \\, [ - \\nabla ^ { m } \\phi _ { + } \\nabla _ { m } \\phi _ { + } + \\nabla ^ { m } \\phi _ { - } \\nabla _ { m } \\phi _ { - } - m ^ { 2 } ( \\phi _ { + } + \\phi _ { - } ) ^ { 2 } ] .\n",
      "Predicted Formula: { \\mathrm } = \\int _ { { 2 } } \\sqrt { _ _ _ { 2 } x { x R } ^ ^ { \\mu } } { { i } ^ ^ _ { 2 } x { { i } } { { \\mu } } { { 2 } } { _ { 2 } } { _ { 2 } ^ ^ _ { 2 } } { { 2 } } { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\ \\ \\dot { A } } ^ { C } \\overline { { R } } = 6 \\alpha \\left( \\nabla _ { \\ \\ \\dot { A } } ^ { C } W ^ { 2 } \\right) \\overline { { \\nabla } } ^ { 2 } \\overline { { W } } ^ { 2 } + 6 \\alpha W ^ { 2 } \\overline { { \\nabla } } ^ { 2 } \\nabla _ { \\ \\ \\dot { A } } ^ { C } \\overline { { W } } ^ { 2 } + { \\cal O } \\left( \\alpha ^ { 2 } \\right)\n",
      "Predicted Formula: { \\rho } } } G } ^ { { ( } ( { { } } { { { _ ^ { _ { \\mu } ^ ^ A } ^ ^ { A } { { { - } } _ { W W W _ { { A } } A { W W W { { A } } ^ _ ^ _ W \\prime } } _ { W } { { { A } } { { A } } ^ A } ^ ^ { A } _ { { _ } _ { { A } } \\overline _ } } _ { _ { \\prime } } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( { \\phi } ) = { M ^ { - 2 } } _ { P l } \\int { \\frac { V } { V ^ { \\prime } } d { \\phi } }\n",
      "Predicted Formula: \\frac ) } { = { { { { 2 } } } { { 2 } { { { { \\partial } { { } { \\prime } } { ^ { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\alpha _ { m } ^ { \\mu } , \\alpha _ { n } ^ { \\nu } ] = m \\delta _ { m , - n } \\eta ^ { \\mu \\nu } .\n",
      "Predicted Formula: ^ { 0 } ^ { 2 } } _ _ { \\nu } , { \\prime } , = { { { { \\nu } ^ } } } { { \\nu } } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 1 } = q _ { 2 } = q _ { 3 } + q _ { 4 } = 2 \\ell \\; , \\quad J = 0 \\; .\n",
      "Predicted Formula: { n } , - _ { 2 } } { _ { 2 } } _ _ { 2 } } _ _ _ { _ _ { ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) \\, \\xi _ { \\bf p } ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) = p _ { 0 } \\, \\xi _ { \\bf p } ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) , \\quad { \\bf P } ^ { ( 0 ) } ( { \\alpha } , { \\bf n ) } \\, { \\xi } _ { \\bf p } ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) = { \\bf p } \\, { \\xi } _ { \\bf p } ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) .\n",
      "Predicted Formula: { 2 } ) ^ { { _ ^ X { ^ { } } ^ { ^ { n } } ( { ( } ) } \\xi \\xi ) p ) ^ \\xi \\xi } } ^ { { { n } ^ \\xi \\, { p } } } \\xi ( } ) ^ \\xi \\xi ^ \\xi \\xi \\xi \\xi \\xi p } ^ { \\xi \\xi \\xi } \\xi \\xi ( } ^ \\xi \\xi \\xi ^ p \\xi ^ \\xi \\xi p ^ ^ \\xi \\xi { \\xi \\xi } } \\xi { ( } ^ \\xi \\xi \\xi _ p \\xi ^ \\xi \\xi p ^ { { { { } { \\xi \\xi \\xi { \\xi p } } { { ( } ) \\xi \\xi \\xi ^ p \\xi \\xi \\xi \\xi p ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: { \\rho } ( r ; x ) = \\frac { \\partial } { \\partial x } \\rho ( r ; x ) .\n",
      "Predicted Formula: G } = { ) = ) = = \\frac 1 } { \\partial } { { \\partial { ) { ) ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { 1 } ( d P _ { 9 } , { \\cal { O } } _ { d P _ { 9 } } ( 9 \\sigma | _ { d P _ { 9 } } - F ) ) | _ { c _ { - 3 } } = 2 .\n",
      "Predicted Formula: { \\mu } = \\eta ) = { 2 } ^ ^ _ { } } _ { { 4 } ^ } 9 } , ^ { _ = { { 0 } ^ { 9 } ) ^ { { { > 4 } } 0 } } } { _\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 5 } ^ { \\mu \\nu } = - i e ^ { 2 } M _ { 5 } ^ { \\mu \\nu } ,\n",
      "Predicted Formula: { \\mathrm } ^ { ( } { = { { { { { - } } { { \\nu } ^ ( } =\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 1 , 2 } \\times \\Phi _ { 1 , 2 } = \\Phi _ { 1 , 1 } + \\Phi _ { 1 , 3 }\n",
      "Predicted Formula: { \\mu } ^ } } \\equiv _ { i } } } } { { { i } , } } { { { 2 } \\kappa \\kappa = {\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\begin{array} { l } { x ^ { \\prime } = D ( \\Lambda , u ) x } \\\\ { u ^ { \\prime } = D ( \\Lambda , u ) u } \\\\ \\end{array} \\right.\n",
      "Predicted Formula: { l } l { _ { i } } } } { ^ { } { { { { } } { 2 } } & , { ) { , { { { \\end{array}\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( D _ { i \\alpha } W _ { ~ \\gamma } ^ { \\beta } - \\delta _ { \\alpha } ^ { ~ \\beta } D _ { i \\gamma } W _ { ~ \\delta } ^ { \\delta } ) = D _ { i \\delta } W _ { ~ \\{ \\alpha } ^ { \\delta } \\delta _ { ~ \\gamma \\} } ^ { \\beta } - D _ { i \\{ \\alpha } W _ { ~ \\gamma \\} } ^ { \\beta } - 3 D _ { i \\{ \\alpha } \\delta _ { ~ \\gamma \\} } ^ { \\beta } W _ { ~ \\delta } ^ { \\delta }\n",
      "Predicted Formula: _ _ { 1 } } } _ { i } , { { i } ) { _ { i } } ^ i } } } _ { i } } } { { i } } ^ { i } _ { { \\pi { i } } ^ { { i } } _ } { i } _ i _ i } ^ ^ \\prime } ( _ { i } } _ } ^ { i } ^ { ^ _ \\prime } ( { _ ^ { i } } _ } ^ { i } ^ { ^ ^ \\prime } ( { { i } ^ ^ { i } _ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { A } = c ^ { A \\alpha } Z ^ { \\alpha } , \\; \\; F _ { A } = c ^ { A \\alpha } \\omega _ { \\alpha \\beta } Z ^ { \\beta } .\n",
      "Predicted Formula: { M } = { ^ { 2 } { { { { A } { { \\; \\; { \\mu } ^ , A } { { { A } ^ ^ \\prime }\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { p h } ( t ) = \\Lambda _ { 0 } - \\frac { m _ { F } ^ { 4 } \\, \\, U ^ { 2 } ( t ) } { 2 f ( t ) } + \\frac { 2 \\, m _ { F } ^ { 4 } } { ( 4 \\pi ) ^ { 2 } } \\; \\int _ { 0 } ^ { t } U ^ { 2 } ( t ) d t - \\frac { 2 } { ( 4 \\pi ) ^ { 2 } } \\, \\sum _ { i } \\, N _ { i } \\int _ { o } ^ { t } m _ { i } ^ { 4 } ( t ) \\, d t \\, ,\n",
      "Predicted Formula: { 0 } = = p ) { \\frac { { p } ^ { _ \\kappa } { p } } { 2 } } { _ \\, { 2 } } { ) { { { ^ } { ) } \\leq { _ \\kappa } } } { \\Lambda } } { 2 } } { { } ) ) ^ \\leq 2 } } { { { 0 } ^ \\infty } } { 2 } } ) { { { { { p } { 4 } \\pi ) { \\leq 2 } } { { { k } \\cong { { f } ^ { ^ 0 } } { ( } } { { f } } { ( } } { _ { \\leq { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 2 } : = \\{ y _ { 2 } = 0 \\} \\cong { \\mathbb P } ^ { 2 } ( x ) ,\n",
      "Predicted Formula: { 0 } = = \\mapsto _ { 0 } , { , { } 2 } } _\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { B _ { 2 } } \\left( \\kappa _ { 2 } \\, u _ { \\mu \\nu } ^ { 0 } ( x ) T ^ { \\mu \\nu } + \\kappa _ { 2 } \\sum _ { n = 1 } ^ { \\infty } \\frac { \\psi _ { n } ( R ) e ^ { 2 k R } } { N _ { 0 } } \\, u _ { \\mu \\nu } ^ { n } ( x ) T ^ { \\mu \\nu } - \\frac { \\kappa _ { 1 } } { \\sqrt { 3 } } \\varphi \\, T _ { \\mu } ^ { \\mu } \\right) d z .\n",
      "Predicted Formula: { 0 } } 1 } } { { \\frac { 2 } } { _ { 1 } } ^ { 2 } } { _ { { { \\nu } } \\right\\rangle { _ { \\nu } } { \\nu } } } ^ { \\infty } } { \\partial } { \\nu } { { _ { { { i } } } { { _ { \\nu } } { \\nu } } ^ { ( } } _ { { \\nu } \\psi \\psi _ \\partial } { \\nu } } { { _ _ } } ^ { { \\mu } } \\nu } } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mathrm { T } } ( s ) = \\sum _ { m = - \\infty } ^ { \\infty } \\sum _ { \\{ k \\} } \\left( \\Omega _ { m } ^ { 2 } + \\omega _ { k } ^ { 2 } \\right) ^ { - s } { , }\n",
      "Predicted Formula: { s } e } } = \\frac ) = \\sum \\sum { i \\in } } } ^ \\infty } } { i \\in _ } _ { n } ^ ( } _ { i } k } } k } } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: F , G ] ( { \\bf x , y } ) = \\int { d ^ { 3 } z \\: [ F ( { \\bf x , z } ) G ( { \\bf z , y } ) - G ( { \\bf x , z } ) F ( { \\bf z , y } ) ] } .\n",
      "Predicted Formula: ( { ^ = ( _ } } } ) = { = { { { { ( } x x { ( ( { , } } , ) { { { { , } } } ) { ) ( { { , } } , ) , { { { , } } ( ) { { ( \\left( \\left(\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\cal W } = h \\left( Q ^ { 1 } Q ^ { 2 } Q ^ { 3 } + Q ^ { 4 } Q ^ { 5 } Q ^ { 6 } + Q ^ { 7 } Q ^ { 8 } Q ^ { 9 } + \\tilde { Q } _ { 1 } \\tilde { Q } _ { 2 } \\tilde { Q } _ { 3 } + \\tilde { Q } _ { 4 } \\tilde { Q } _ { 5 } \\tilde { Q } _ { 6 } + \\tilde { Q } _ { 7 } \\tilde { Q } _ { 8 } \\tilde { Q } _ { 9 } \\right) \\, ,\n",
      "Predicted Formula: { } _ { { { { { 2 } ( \\eta { 2 } } \\eta { 2 } W ^ ^ { 2 } \\! + { 2 } } ^ { 2 } W { ^ { 2 } } ^ { 2 } W \\eta { 2 } } { ^ Q } _ { 7 } \\cdots { Q } _ { 4 } } ^ Q } { { 4 } ^ { _ Q } _ { 4 } } { Q } _ { 4 } ^ { Q } _ { 4 } ^ { { Q } _ { 4 } } { Q } } { 4 } } { Q } } { 4 } } { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mathrm { e f f } } = V _ { \\mathrm { S U S Y } } ( y _ { i } ) + V _ { \\mathrm { S o f t } } ( y _ { i } ) + V _ { \\mathrm { Q u a r t i c } } ( y _ { i } ) .\n",
      "Predicted Formula: { 0 } p } f } } f { { { i } f f } } } } { { ) \\! S } ) { f { { i } Y i Y y } } ^ { ) \\! i } ) _ _ { i } S i } f } i } } ) i } )\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { i } ^ { \\mathrm { d i m } ( T P ) ^ { \\mathrm { v e r t i c a l } } } C ^ { \\dagger } .\n",
      "Predicted Formula: { 0 } = = i } i i = } = = ) = ) = i } i i } = = = = = } } = { { { ( } ( =\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\phi _ { k } \\, , \\, \\phi _ { h } ] = - { \\frac { i \\pi \\beta ^ { 2 } } { 2 } } s \\left( \\frac { k - h } { 2 N } \\right) \\quad , \\quad [ \\bar { \\phi } _ { k } \\, , \\, \\bar { \\phi } _ { h } ] = { \\frac { i \\pi \\beta ^ { 2 } } { 2 } } s \\left( \\frac { k - h } { 2 N } \\right) \\quad , \\quad [ \\phi _ { k } \\, , \\, \\bar { \\phi } _ { h } ] = 0 \\quad .\n",
      "Predicted Formula: _ { i } , { _ _ \\, { 2 } { { { \\frac \\frac { \\kappa } { { { 2 } } { { } \\pi { { { _ i } { } { 4 } \\pi { { { _ _ ( \\pi } _ \\bar i } } { _ _ \\, \\pi } { \\bar i } } { i \\frac { \\kappa } { { { \\prime } } { 4 } } { { { { i } { } { { } } { { _ ( ( { i } } { \\, \\pi } } \\bar i } } { i i _\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { i } = \\zeta _ { i } - \\frac { \\sum _ { k } \\zeta _ { k } n _ { k } } { \\sum _ { l } n _ { l } } .\n",
      "Predicted Formula: { r } = { \\frac { i } } { \\frac \\left| } { i } } { { i } } { { k } } { { _ { i } } { { i } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: = { \\bar { A } } ( u ) e x p \\bigg \\{ + \\int \\kappa s n u d u \\bigg \\} .\n",
      "Predicted Formula: { { { \\pi } { { { ) { { { { { \\frac _ { { { { { { ^ { \\bigg {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mu } \\theta _ { m } ^ { \\mu } ( t ) = n _ { \\mu } { \\frac { \\partial L _ { ( m ) } } { \\partial \\nabla _ { \\mu } \\phi } } { \\cal L } _ { t } \\phi = - N { \\frac { \\partial L _ { ( m ) } } { \\partial \\dot { \\phi } } } { \\cal L } _ { t } \\phi ~ ~ ~ ,\n",
      "Predicted Formula: { n } } \\frac { \\perp } = = 2 } } = _ = = \\begin{matrix} { i } } { } 1 } { { n } ) } } { \\partial } ^ { n } } ^ { { _ } _ { m } } { { _ _ { } \\partial } { { n } ) } } { { } { \\theta } } { { { } } _ i } } { { ~ ~ ~\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\frac { 1 } { 2 } \\left( { p _ { x } } ^ { 2 } + { p _ { y } } ^ { 2 } + \\frac { x ^ { 2 } } { m ^ { 2 } } + \\frac { y ^ { 2 } } { n ^ { 2 } } \\right) ,\n",
      "Predicted Formula: { \\frac 1 } { 2 } { { \\frac { { 2 } } { { 2 } } { _ { { 2 } ^ { { 2 } } \\frac _ p } { 2 } } { { _ { 2 } } { { _ p } { 2 } } { { _ { 2 } } { { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( { \\bf k } , t ) = b _ { \\mathrm { E } } ( 1 , { \\bf k } , t ) , \\qquad d ( { \\bf k } , t ) = b _ { \\mathrm { E } } ( - 1 ,\n",
      "Predicted Formula: { _ } } ) ) \\bf { ( ( { k } \\bf } } { { \\bf , \\bf } } ) _ \\bf , ( ( \\bf \\bf } } ) ) \\bf , ( ( { 2 } \\bf r ( ( \\bf \\bf , ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 4 } = \\frac { 3 D } { 2 } e ^ { - 2 \\phi } e ^ { 2 \\chi } c \\partial c { \\partial } ^ { 2 } c .\n",
      "Predicted Formula: { j } = { _ 1 } { { { } \\pi { { 2 } } } { { 2 } } } { { { } } \\partial 2 } } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: d ^ { 6 } z \\Phi ^ { 2 } \\Box \\Phi = \\frac { 1 } { 1 6 } \\int d ^ { 6 } z \\Phi ^ { 2 } \\bar { D } ^ { 2 } D ^ { 2 } \\Phi = - \\frac { 1 } { 4 } \\int d ^ { 8 } z \\Phi ^ { 2 } D ^ { 2 } \\Phi .\n",
      "Predicted Formula: { { 4 } x { { { 2 } = = { { , 1 } { 4 } \\pi ^ \\Gamma { ^ 4 } } { { { 2 } } ^ z } } ^ 2 } } \\bar { 2 } } \\bar { , { 3 } { 4 } } 4 { { 4 } } 4 { { 2 } } \\bar { 3 } } \\bar {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { i } ^ { 2 } = \\frac { 1 } { 4 } b _ { i } - \\frac { 1 } { 2 4 } \\sum _ { j } b _ { j } ,\n",
      "Predicted Formula: { 0 } = = i } = = \\frac i } { 2 } } { { i } } _ i } { 4 } } } { { i } } { { j } } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { - ^ { \\prime } } = \\frac { { \\bf x } ^ { 2 } } 2 , \\quad p ^ { - ^ { \\prime } } = \\left( { \\bf x } \\cdot { \\bf p } - x ^ { - } p ^ { + } \\right) , \\quad p ^ { - } = \\frac { { \\bf p } ^ { 2 } } { 2 p ^ { + } } .\n",
      "Predicted Formula: { 2 } } \\prime } } = x \\frac 1 } } } } { \\prime } } { { { } { { \\prime } } \\prime } } { { , { { } } { \\bf } } } { \\bf { \\prime } } { { \\prime } } { { { 2 } } { { p } } } } { \\prime } } } } { 2 } } { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: U ( t ) f ) ( x ) = \\int _ { M } d y \\, K ( x , y ; t ) f ( y )\n",
      "Predicted Formula: ) { ) = ( { = ) = ( ( { 0 } ^ ^ ^ f \\, { ) y ) { ) ) { ) y\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mu \\nu } \\rightarrow \\tilde { G } _ { \\mu \\nu } = \\frac { 1 } { 2 } e ^ { - 2 \\phi } \\epsilon _ { \\mu \\nu \\rho \\sigma } G ^ { \\rho \\sigma } , \\, \\phi \\rightarrow - \\phi ,\n",
      "Predicted Formula: { n } } = = ^ \\mu } { { \\nu } } } { _ 1 } { \\sqrt } } { { i } } } { { { \\nu \\nu } } } ^ { { \\nu } } { \\nu \\, { ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { H } \\equiv { \\frac { 2 } { f ^ { \\prime } ( r _ { + } ) } } = { \\frac { r _ { + } l ^ { 2 } } { r _ { + } ^ { 2 } + | r _ { - } | ^ { 2 } } }\n",
      "Predicted Formula: { 0 } = = { { 1 } } { } { 2 } } } _ { r } ^ { { { { { { r } { r } } { { 2 } } { { } { 2 } } { 2 } } { { { { r } } { { 2 } } { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { A } ^ { M } ( g ) = L _ { A } ^ { M } ( g h , h ) | _ { h = e } \\, , \\quad \\overline { { L } } _ { M } ^ { A } ( g ) = \\overline { { L } } _ { M } ^ { A } ( h , g h ) | _ { h = e } \\, ,\n",
      "Predicted Formula: { M } = _ \\prime } { x ) { F _ { \\perp } } { ( } } { ) { { ) { { { a } ^ } { { { } } { { { \\perp } } { 2 } } { ) { { { { } } } \\overline A } } ^ ( } } { ) { ) { { { { \\mu } } } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: { \\rho ( t ) = \\ut _ { ( 2 ) } \\rho S ( \\ut _ { ( 1 ) } ) } .\n",
      "Predicted Formula: \\displaystyle } = ) = ( { { 0 } ) } ( ^ { { - } 0 } ) } } { { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 0 } ^ { 2 \\pi } d x ^ { \\prime } \\, K _ { S ^ { 1 } } ^ { \\omega } ( x ^ { \\prime \\prime } , x ^ { \\prime } ; t ^ { \\prime } ) \\, K _ { S ^ { 1 } } ^ { \\omega } ( x ^ { \\prime } , x ; t ) = K _ { S ^ { 1 } } ^ { \\omega } ( x ^ { \\prime \\prime } , x ; t + t ^ { \\prime } )\n",
      "Predicted Formula: { 0 } ^ { \\infty } = } { ^ { 2 } } ^ ^ { \\mu } ^ \\prime } } { { \\infty } { { ^ { \\prime } ) } ^ ^ { \\prime } ) x ) = \\prime } ) x { \\, { 0 } ^ \\prime } } { { \\prime } x { ) { \\prime } ) = ) { ) = , { 3 } , \\prime } , 2 } { , { i } ) ) { ) ^ ) \\prime } )\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { r } = = - \\frac a { r ^ { 2 } + a ^ { 2 } } I _ { \\phi } .\n",
      "Predicted Formula: { 0 } = { \\frac \\frac \\frac r { } } 2 } } _ _ { 2 } } r r { r } ^\n",
      "--------------------------------------------------\n",
      "Actual Formula: n ^ { A } = \\frac { d \\phi ^ { A } } { | | \\phi | | } + \\phi ^ { A } d \\left( \\frac 1 { | | \\phi | | } \\right) ,\n",
      "Predicted Formula: { { 2 } = { \\frac 1 } { { 2 } { { 2 } { } { { { { { { 2 } { { { { \\partial { } ^ } { } } { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: j _ { \\mu } ( x _ { 1 } ) j _ { \\nu } ( x _ { 2 } ) \\rangle , \\qquad \\langle T _ { \\mu \\nu } ( x _ { 1 } ) T _ { \\rho \\sigma } ( x _ { 2 } ) \\rangle\n",
      "Predicted Formula: \\mid { 1 } } x _ y \\perp } ) x { ( a } ( x ) { \\nu } ) x { { _ _ { a } } ( { ) y a } ) x { { a } } x x _ y a } ) x (\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { ~ b } ^ { a } ( z ) = \\displaystyle { \\delta _ { ~ b } ^ { a } + 4 i \\frac { 1 } { x _ { - } ^ { 2 } } \\theta ^ { a } x _ { - } { \\cdot \\sigma } \\bar { \\theta } _ { b } }\n",
      "Predicted Formula: { \\underline } } = { 2 } = { ) = \\frac \\frac \\frac { { a } ~ { { 2 } ( _ { \\partial } { 2 } { i } } 2 } } { 2 } { j } } } } { z } { i } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 1 2 } = \\left( \\frac { i \\hbar } { 2 } \\right) \\sum _ { i = 1 } ^ { m } \\left( \\frac { \\partial } { \\partial q _ { 1 } ^ { i } } \\frac { \\partial } { \\partial p _ { 2 } ^ { i } } - \\frac { \\partial } { \\partial p _ { 1 } ^ { i } } \\frac { \\partial } { \\partial q _ { 2 } ^ { i } } \\right) .\n",
      "Predicted Formula: { 0 } \\cdots } { \\frac { 1 } { { 2 } \\left( { { { i } } } } { 2 } } { { i } { \\partial \\xi { { i } } { 2 } } { { \\partial } { \\partial \\xi { { i } } \\left( \\infty } } { { { p } { \\partial \\xi { { i } \\right) { \\infty } } { { p } { \\partial \\xi { { i } } { \\infty } } { { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mu \\nu } ( x ) = h _ { \\mu \\nu } ^ { ( m ) } ( x ) + \\frac { 2 } { \\ell } \\, \\eta _ { \\mu \\nu } \\, \\hat { \\xi } \\, ^ { 5 } ( x ) \\, ,\n",
      "Predicted Formula: { i } } = = ) = = , { \\mu } } ^ ^ ( } ) } ^ x ^ { { _ \\kappa } } { } { { _ { \\nu } } } \\mu } \\xi \\xi \\xi 2 } \\xi \\xi \\xi \\xi\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\bf L } = - \\int R ^ { 2 } d \\Omega \\, \\biggl \\{ \\dot { f } \\, ( { \\bf r } \\times \\nabla ) f + f ^ { 2 } \\, ( \\dot { \\theta } + A _ { 0 } ) \\, { \\bf r } \\times ( \\nabla \\theta + { \\bf A } ) - \\rho _ { e } \\, { \\bf r } \\, ( { \\bf r } \\cdot \\nabla \\times { \\bf A } ) \\biggr \\} .\n",
      "Predicted Formula: { } _ { { \\frac ^ { 2 } } ^ { { ^ { { R } } { \\, ^ } } } ^ ^ { { { ( { 2 } } r ^ \\bf r } ^ { ^ { i } ) { { { { } { { \\bf \\bf { { \\bf } } } { { _ { i } } { \\, } } { { \\, \\bf } } ) ^ \\bf { ) } } } ^ { A ^\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\frac { 1 } { \\sqrt { 2 } } \\Big ( ( 1 + \\gamma _ { 5 } ) \\psi + ( 1 - \\gamma _ { 5 } ) \\tilde { \\psi } \\Big ) .\n",
      "Predicted Formula: { { 1 } { 2 } 2 } } { { \\begin{array} ^ ^ ^ \\frac { \\mu } ) ^ { { { _ \\cdots ) { 5 } ) { \\psi } _ { _ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { ( 1 ) } = - l _ { 0 } ^ { 2 } K _ { a } ^ { b } K _ { b } ^ { a } .\n",
      "Predicted Formula: { \\prime } ) = = y \\begin{array} ^ { i } ^ ( } } { \\mu } } 2 } } { a } } ( } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: { n T _ { 0 } ^ { 3 } } { g _ { \\mathrm { e f f } } } = \\frac { T _ { 0 } ^ { 3 } } { g } \\sqrt { n ^ { 2 } + q ^ { 2 } + g ^ { 2 } \\, ( p - \\chi _ { 0 } q ) ^ { 2 } } \\, \\left( 1 + q ^ { 2 } / n ^ { 2 } \\right) ^ { - 1 } .\n",
      "Predicted Formula: d } { { 2 } } { 2 } } { { _ { 4 } e } } } } { { { \\frac r } { 2 } } { 2 } } { { } { { f } } 2 } } { _ { 2 } } { _ { 2 } } } _ _ { ) { 2 } } { { { 2 } } } { ^ { \\frac { 2 } } { } { 2 } } { 2 } } \\cdots {\n",
      "--------------------------------------------------\n",
      "Actual Formula: { \\mit \\Omega } = - S \\delta \\Theta - { \\cal P } _ { i } \\, \\delta v ^ { i } \\ , \\qquad \\delta F = - S \\delta \\Theta + v ^ { i } \\delta { \\cal P } _ { i } \\ , \\qquad \\delta U = \\Theta \\delta S + v ^ { i } \\delta { \\cal P } _ { i } \\ .\n",
      "Predicted Formula: { { } { { { { { { { { { } } { i } } { { { \\prime } , { { { { , } { { { , { 2 } , { } } _ i } , { { { , { _ { _ { i } } { { } } } ^ i } ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 1 } ( x ) \\to \\sqrt { { \\frac { \\pi } { 2 x } } } e ^ { - x } ( 1 + { \\frac { 3 } { 8 x } } + \\cdots ) ,\n",
      "Predicted Formula: { 2 } ^ { ) = \\frac \\frac - } } 2 } { { } } { - { { { - } } { { ) } ) } 2 } { { } } { - { \\frac { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: s _ { \\mathrm { d u a l } } ^ { 2 } = ( N e ^ { \\phi } ) ^ { 2 / ( p - 7 ) } d s _ { \\mathrm { s t r i n g } } ^ { 2 } .\n",
      "Predicted Formula: ^ { \\mu } \\scriptsize } } = } } = { 2 } } = ^ ^ { { - } { ^ { 2 } } } ^ { } } ^ 0 } e } } } } } } 2 } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\widehat { n } | \\widehat { n ^ { \\prime } } > = - 2 \\delta _ { n + n ^ { \\prime } } + \\delta _ { n + n ^ { \\prime } + 1 } + \\delta _ { n + n ^ { \\prime } - 1 }\n",
      "Predicted Formula: > > } } { > x } } 2 } } ^ { { , ^ ^ { 2 } } } } 2 } } ^ ^ { m } ^ } } \\prime } } ^ ^ { { { n } ^ } } \\prime } } _ ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: L _ { n } , f ] = z ^ { n + 1 } \\partial _ { z } f .\n",
      "Predicted Formula: _ { 0 } = { _ { f _ { 2 } } } } { i } } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\le k _ { \\mathrm { m i n } } = n _ { \\mathrm { M } } ^ { 1 / 3 }\n",
      "Predicted Formula: { \\underbrace { i } e } } } } { { i } e } } } } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\lambda } ( q ) \\equiv \\sum _ { \\mu \\in W _ { \\lambda } } e ^ { 2 i a \\mu \\cdot q } ,\n",
      "Predicted Formula: { 0 } = { ) = = _ { p \\in , _ { W } , { { { i } } W { { } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\pm } X _ { \\mu } \\psi _ { \\pm } ^ { \\mu , j } = \\partial _ { \\pm } X _ { \\mu } e ^ { j } \\Psi _ { \\pm } ^ { \\mu } = 0 , ~ ~ ~ ~ ~ ~ ~ ~ j = 1 , 2 . . . 6 .\n",
      "Predicted Formula: { \\mu } = = { 0 } } = { \\mu } = = \\prime } = } = \\psi , { \\mu } ^ ^ { \\mu } , ^ { i } - ^ { \\mu } \\gamma \\mu } , \\gamma _ , ~ ~ ~ ~ ~ ~ ~ ~ { , ^ , ~ .\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { ( i ) } ( x ) = U _ { n } ( \\phi ) \\psi ^ { ( i ) } ( \\rho ) U _ { n } ^ { \\dagger } ( \\phi ) ,\n",
      "Predicted Formula: { ( } ) ) ( = ) = = , { i } ( { ) x { { ( } ) ) ( ) { { i } ( ( } ( ) x\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 0 } ^ { > } = - \\frac { 8 k ^ { 2 } } { \\ell _ { 0 } ^ { 2 } } B _ { 1 } ^ { < } , \\quad \\epsilon _ { 2 } ^ { > } = k ^ { 2 } B _ { 2 } ^ { < } - \\frac { 3 w ^ { ( 2 ) > } k ^ { 2 } } { \\ell _ { 0 } ^ { 2 } } B _ { 1 } ^ { < } \\, .\n",
      "Predicted Formula: { \\mu } = { \\prime } } { \\frac { \\kappa } { { 2 } } { 4 } { 4 } } { 2 } } { { { \\mu } \\cdots { 2 } } { _ _ { j } } { 2 } } { \\frac { 2 } } { { \\mu } } { 2 } } { _ \\Gamma } { { 2 } ) } { } { { 2 } } } \\! 2 } } { 2 } } { \\mu } \\cdots { 2 } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: Z ^ { M } = \\eta ^ { \\alpha } \\partial _ { \\alpha } Z ^ { M }\n",
      "Predicted Formula: { { a } = { ^ { 2 } { { { \\mu } } { { \\Lambda } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: { F } _ { i } ^ { a \\dagger } = - { \\frac { \\partial { W } } { \\partial \\tilde { q } _ { i } ^ { a } } } = - \\sqrt { 2 } \\phi _ { a } ^ { b } q _ { b } ^ { i } - m _ { j } ^ { i } q _ { a } ^ { j } = 0 .\n",
      "Predicted Formula: W } _ = \\mu } } { i } = = = \\frac _ { i } { } { { \\partial } { } } } { i } } { 2 } } { { { _ _ { } } { { i } } { a } { { { a } ^ ^ 2 } } _ _ { j } ^ { 2 } k { j } } { 2 } { { _\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\frac { 1 } { R _ { S ^ { 3 } } ^ { 2 } } = \\frac { 2 } { | H _ { 0 } | } = e ^ { 2 \\psi _ { 2 } }\n",
      "Predicted Formula: { { \\Lambda } { 2 \\xi { \\Lambda } } \\prime } } } { \\Lambda } } \\frac \\frac \\Lambda } { { } _ { \\Lambda } } { { { { - } } R } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( R ) = V _ { 0 } + \\sigma R + O ( R ^ { - 1 } ) \\\n",
      "Predicted Formula: { ) { ( ( { R } ( { { { { ^ ( ) ) \\prime } } )\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { \\prime \\prime } ( u ^ { \\prime \\prime } , v ^ { \\prime \\prime } ) = u ^ { \\frac { 1 } { 2 } ( \\alpha _ { 1 } + \\alpha _ { 3 } - \\alpha _ { 2 } - \\alpha _ { 4 } ) } v ^ { \\frac { 1 } { 2 } ( \\alpha _ { 2 } + \\alpha _ { 3 } - \\alpha _ { 1 } - \\alpha _ { 4 } ) } F ( u , v ) .\n",
      "Predicted Formula: { - } = = = ) = \\prime } } = = ) = \\prime \\prime = = = = \\begin{matrix} { \\prime } 1 } } 2 } } v ^ { v } \\cdots v _ { 2 } } v _ { 2 } } v _ { 2 } } v { { 2 } 1 } { v } } v _ { 2 } } v v } 2 } ) v _ { 2 } ^ v _ { 2 } } v { { { _ v _ { {\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m label_to_index \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(label_to_index_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     59\u001b[0m index_to_label \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m label_to_index\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# Reverse the mapping\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_to_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(val_accuracy)\n\u001b[0;32m     63\u001b[0m save_model(model, optimizer, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, val_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, dataloader, criterion, device, index_to_label)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, formulas \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     13\u001b[0m     images, formulas \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), formulas\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformulas\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass images and input sequence\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), formulas[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 49\u001b[0m, in \u001b[0;36mImageToLaTeXModel.forward\u001b[1;34m(self, images, formulas)\u001b[0m\n\u001b[0;32m     46\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(images)  \u001b[38;5;66;03m# Shape: [batch_size, feature_dim]\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Decode to generate the LaTeX expression\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformulas\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Skip the end token\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 34\u001b[0m, in \u001b[0;36mDecoderRNN.forward\u001b[1;34m(self, features, formulas)\u001b[0m\n\u001b[0;32m     31\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((features\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), embeddings), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Pass through GRU and then through the final linear layer\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m gru_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(gru_out)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1392\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1392\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1404\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[0;32m   1405\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1406\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1414\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def decode_formula(indices, index_to_label):\n",
    "    return ' '.join([index_to_label[str(i.item())] for i in indices if i.item() and str(i.item()) != '2'])  # Skip padding\n",
    "\n",
    "\n",
    "def validate_model(model, dataloader, criterion, device, index_to_label):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for images, formulas in dataloader:\n",
    "            images, formulas = images.to(device), formulas.to(device)\n",
    "            outputs = model(images, formulas[:, :-1])  # Pass images and input sequence\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), formulas[:, 1:].contiguous().view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy (if applicable)\n",
    "            predicted_indices = torch.argmax(outputs, dim=2)  # Get the index of the max log-probability\n",
    "            correct_predictions += (predicted_indices == formulas[:, 1:].contiguous()).sum().item()\n",
    "            total_samples += formulas[:, 1:].numel()  # Total number of tokens in the validation batch\n",
    "\n",
    "            # Print images and predictions\n",
    "            for i in range(len(images)):\n",
    "                # Decode the actual and predicted formulas\n",
    "                actual_formula = decode_formula(formulas[i, 1:], index_to_label)  # Skip <S> token\n",
    "                predicted_formula = decode_formula(predicted_indices[i, 1:], index_to_label)  # Skip <S> token\n",
    "                # print(f'Image: {images[i]}')  # This will print the tensor, consider using visualization instead\n",
    "                print(f'Actual Formula: {actual_formula}')\n",
    "                print(f'Predicted Formula: {predicted_formula}')\n",
    "                print('-' * 50)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "# Assuming you have your model, dataloader, criterion, and device set up\n",
    "# Assuming 230k.json is loaded as label_to_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = load_model(model, optimizer)\n",
    "\n",
    "val_dataset = LaTeXDataset('LaTex_data/split_1', mapping_path, label_to_index_path, transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)  # Set shuffle to False for validation\n",
    "label_to_index = json.load(open(label_to_index_path, 'r'))\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}  # Reverse the mapping\n",
    "\n",
    "val_loss, val_accuracy = validate_model(model, val_dataloader, criterion, device, index_to_label)\n",
    "print(val_accuracy)\n",
    "save_model(model, optimizer, epoch + 1, val_loss, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
