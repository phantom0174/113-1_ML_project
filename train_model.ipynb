{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "# print(len(os.listdir('LaTex_data/split_1')))\n",
    "# Paths\n",
    "image_folder_path = \"LaTex_data/generated_png_images\"\n",
    "mapping_path = \"image_formula_mapping.json\"\n",
    "label_to_index_path = \"LaTex_data/230k.json\"\n",
    "\n",
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "folders = [\"split_1\", \"split_2\", \"split_3\", \"split_4\", \"split_5\", \n",
    "           \"split_6\", \"split_7\", \"split_8\", \"split_9\", \"split_10\"]\n",
    "  \n",
    "with open(mapping_path, 'r') as f:\n",
    "  image_formula_mapping = json.load(f)\n",
    "keys = list(image_formula_mapping.keys())\n",
    "\n",
    "# print(image_formula_mapping['0002475406d9932.png'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class LaTeXDataset(Dataset):\n",
    "    def __init__(self, image_folder, mapping_file, label_to_index_file, transform=None, max_images=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load mappings and label-to-index dictionary\n",
    "        with open(mapping_file, 'r') as f:\n",
    "            self.image_formula_mapping = json.load(f)\n",
    "        with open(label_to_index_file, 'r') as f:\n",
    "            self.label_to_index = json.load(f)\n",
    "\n",
    "\n",
    "        # Apply the image count limit if specified\n",
    "        # if max_images:\n",
    "        #     self.image_formula_mapping = dict(list(self.image_formula_mapping.items())[:max_images])\n",
    "\n",
    "        self.index_to_label = {v: k for k, v in self.label_to_index.items()}\n",
    "        self.vocab_size = len(self.label_to_index)\n",
    "        self.formulas = list(self.image_formula_mapping.values())\n",
    "        self.image_files = [f for f in os.listdir(image_folder) ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        image_name = self.image_files[idx]\n",
    "        formula = self.image_formula_mapping[str(image_name)]\n",
    "  \n",
    "        # Load image\n",
    "        image_path = os.path.join(self.image_folder, image_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Tokenize the formula into indices\n",
    "        formula_tokens = formula.split()  # Splitting the formula string by whitespace\n",
    "        formula_indices = []\n",
    "        for token in formula_tokens:\n",
    "            # Map each token to its index; if not found, use a default index (e.g., 0)\n",
    "            index = self.label_to_index.get(token, 0)  # Assuming 0 is for unknown tokens\n",
    "            formula_indices.append(int(index))\n",
    "        \n",
    "        # Convert the list of indices to a 1D tensor\n",
    "        return image, torch.tensor(formula_indices, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder / Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)  # Example using ResNet50\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False  # Freeze ResNet layers\n",
    "\n",
    "        # Replace the final fully connected layer with a custom one\n",
    "        self.resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(resnet.fc.in_features, feature_dim)\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.resnet(images)  # Shape: [batch_size, feature_dim, 1, 1]\n",
    "        features = features.view(features.size(0), -1)  # Flatten to [batch_size, feature_dim]\n",
    "        features = self.fc(features)\n",
    "        return features\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, features, formulas):\n",
    "        # Embed the input formula tokens\n",
    "        embeddings = self.embedding(formulas)\n",
    "\n",
    "        # Concatenate features and embeddings along the sequence dimension\n",
    "        embeddings = torch.cat((features.unsqueeze(1), embeddings), dim=1)\n",
    "        \n",
    "        # Pass through GRU and then through the final linear layer\n",
    "        gru_out, _ = self.gru(embeddings)\n",
    "        outputs = self.fc(gru_out)\n",
    "        return outputs\n",
    "\n",
    "class ImageToLaTeXModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(ImageToLaTeXModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, images, formulas):\n",
    "        # Encode the images\n",
    "        features = self.encoder(images)  # Shape: [batch_size, feature_dim]\n",
    "        \n",
    "        # Decode to generate the LaTeX expression\n",
    "        outputs = self.decoder(features, formulas[:, :-1])  # Skip the end token\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Separate images and formulas from the batch\n",
    "    images, formulas = zip(*batch)\n",
    "\n",
    "    # Stack images (assumes images are already the same size after transforms)\n",
    "    images = torch.stack(images)\n",
    "\n",
    "    # Pad formulas to the length of the longest formula in the batch\n",
    "    formulas = pad_sequence(formulas, batch_first=True, padding_value=1)  \n",
    "\n",
    "    return images, formulas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save / Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming 'model' is your model and 'optimizer' is your optimizer\n",
    "def save_model(model, optimizer, epoch, loss, filename='model.pth'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, filename)\n",
    "def load_model(model, optimizer, filename='model.pth'):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return epoch, loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bibby\\AppData\\Local\\Temp\\ipykernel_25984\\3498543355.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('model_checkpoint.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from folder 7, epoch 6, with loss 0.7264\n",
      "Training on folder: split_7\n",
      "Folder [7/10], Epoch [7/10], Step [0/732], Loss: 0.8382\n",
      "Folder [7/10], Epoch [7/10], Step [100/732], Loss: 0.5411\n",
      "Folder [7/10], Epoch [7/10], Step [200/732], Loss: 0.6833\n",
      "Folder [7/10], Epoch [7/10], Step [300/732], Loss: 0.4751\n",
      "Folder [7/10], Epoch [7/10], Step [400/732], Loss: 0.3448\n",
      "Folder [7/10], Epoch [7/10], Step [500/732], Loss: 0.4810\n",
      "Folder [7/10], Epoch [7/10], Step [600/732], Loss: 0.3525\n",
      "Folder [7/10], Epoch [7/10], Step [700/732], Loss: 0.5938\n",
      "Folder [7/10], Epoch [8/10], Step [0/732], Loss: 0.8452\n",
      "Folder [7/10], Epoch [8/10], Step [100/732], Loss: 0.5465\n",
      "Folder [7/10], Epoch [8/10], Step [200/732], Loss: 0.6942\n",
      "Folder [7/10], Epoch [8/10], Step [300/732], Loss: 0.4644\n",
      "Folder [7/10], Epoch [8/10], Step [400/732], Loss: 0.3474\n",
      "Folder [7/10], Epoch [8/10], Step [500/732], Loss: 0.4776\n",
      "Folder [7/10], Epoch [8/10], Step [600/732], Loss: 0.3479\n",
      "Folder [7/10], Epoch [8/10], Step [700/732], Loss: 0.5872\n",
      "Folder [7/10], Epoch [9/10], Step [0/732], Loss: 0.8350\n",
      "Folder [7/10], Epoch [9/10], Step [100/732], Loss: 0.5433\n",
      "Folder [7/10], Epoch [9/10], Step [200/732], Loss: 0.6877\n",
      "Folder [7/10], Epoch [9/10], Step [300/732], Loss: 0.4604\n",
      "Folder [7/10], Epoch [9/10], Step [400/732], Loss: 0.3418\n",
      "Folder [7/10], Epoch [9/10], Step [500/732], Loss: 0.4735\n",
      "Folder [7/10], Epoch [9/10], Step [600/732], Loss: 0.3515\n",
      "Folder [7/10], Epoch [9/10], Step [700/732], Loss: 0.5819\n",
      "Folder [7/10], Epoch [10/10], Step [0/732], Loss: 0.8210\n",
      "Folder [7/10], Epoch [10/10], Step [100/732], Loss: 0.5449\n",
      "Folder [7/10], Epoch [10/10], Step [200/732], Loss: 0.6868\n",
      "Folder [7/10], Epoch [10/10], Step [300/732], Loss: 0.4523\n",
      "Folder [7/10], Epoch [10/10], Step [400/732], Loss: 0.3403\n",
      "Folder [7/10], Epoch [10/10], Step [500/732], Loss: 0.4673\n",
      "Folder [7/10], Epoch [10/10], Step [600/732], Loss: 0.3500\n",
      "Folder [7/10], Epoch [10/10], Step [700/732], Loss: 0.5823\n",
      "Training on folder: split_8\n",
      "Folder [8/10], Epoch [1/10], Step [0/732], Loss: 0.2804\n",
      "Folder [8/10], Epoch [1/10], Step [100/732], Loss: 0.5865\n",
      "Folder [8/10], Epoch [1/10], Step [200/732], Loss: 0.7734\n",
      "Folder [8/10], Epoch [1/10], Step [300/732], Loss: 0.6563\n",
      "Folder [8/10], Epoch [1/10], Step [400/732], Loss: 0.8844\n",
      "Folder [8/10], Epoch [1/10], Step [500/732], Loss: 0.9212\n",
      "Folder [8/10], Epoch [1/10], Step [600/732], Loss: 0.5782\n",
      "Folder [8/10], Epoch [1/10], Step [700/732], Loss: 0.7795\n",
      "Folder [8/10], Epoch [2/10], Step [0/732], Loss: 0.2702\n",
      "Folder [8/10], Epoch [2/10], Step [100/732], Loss: 0.5561\n",
      "Folder [8/10], Epoch [2/10], Step [200/732], Loss: 0.7250\n",
      "Folder [8/10], Epoch [2/10], Step [300/732], Loss: 0.6169\n",
      "Folder [8/10], Epoch [2/10], Step [400/732], Loss: 0.8364\n",
      "Folder [8/10], Epoch [2/10], Step [500/732], Loss: 0.8819\n",
      "Folder [8/10], Epoch [2/10], Step [600/732], Loss: 0.5632\n",
      "Folder [8/10], Epoch [2/10], Step [700/732], Loss: 0.7540\n",
      "Folder [8/10], Epoch [3/10], Step [0/732], Loss: 0.2640\n",
      "Folder [8/10], Epoch [3/10], Step [100/732], Loss: 0.5395\n",
      "Folder [8/10], Epoch [3/10], Step [200/732], Loss: 0.6997\n",
      "Folder [8/10], Epoch [3/10], Step [300/732], Loss: 0.5971\n",
      "Folder [8/10], Epoch [3/10], Step [400/732], Loss: 0.8134\n",
      "Folder [8/10], Epoch [3/10], Step [500/732], Loss: 0.8506\n",
      "Folder [8/10], Epoch [3/10], Step [600/732], Loss: 0.5514\n",
      "Folder [8/10], Epoch [3/10], Step [700/732], Loss: 0.7333\n",
      "Folder [8/10], Epoch [4/10], Step [0/732], Loss: 0.2608\n",
      "Folder [8/10], Epoch [4/10], Step [100/732], Loss: 0.5298\n",
      "Folder [8/10], Epoch [4/10], Step [200/732], Loss: 0.6915\n",
      "Folder [8/10], Epoch [4/10], Step [300/732], Loss: 0.5920\n",
      "Folder [8/10], Epoch [4/10], Step [400/732], Loss: 0.7982\n",
      "Folder [8/10], Epoch [4/10], Step [500/732], Loss: 0.8300\n",
      "Folder [8/10], Epoch [4/10], Step [600/732], Loss: 0.5420\n",
      "Folder [8/10], Epoch [4/10], Step [700/732], Loss: 0.7224\n",
      "Folder [8/10], Epoch [5/10], Step [0/732], Loss: 0.2608\n",
      "Folder [8/10], Epoch [5/10], Step [100/732], Loss: 0.5214\n",
      "Folder [8/10], Epoch [5/10], Step [200/732], Loss: 0.6704\n",
      "Folder [8/10], Epoch [5/10], Step [300/732], Loss: 0.5811\n",
      "Folder [8/10], Epoch [5/10], Step [400/732], Loss: 0.7754\n",
      "Folder [8/10], Epoch [5/10], Step [500/732], Loss: 0.8192\n",
      "Folder [8/10], Epoch [5/10], Step [600/732], Loss: 0.5361\n",
      "Folder [8/10], Epoch [5/10], Step [700/732], Loss: 0.7166\n",
      "Folder [8/10], Epoch [6/10], Step [0/732], Loss: 0.2584\n",
      "Folder [8/10], Epoch [6/10], Step [100/732], Loss: 0.5147\n",
      "Folder [8/10], Epoch [6/10], Step [200/732], Loss: 0.6629\n",
      "Folder [8/10], Epoch [6/10], Step [300/732], Loss: 0.5779\n",
      "Folder [8/10], Epoch [6/10], Step [400/732], Loss: 0.7571\n",
      "Folder [8/10], Epoch [6/10], Step [500/732], Loss: 0.8130\n",
      "Folder [8/10], Epoch [6/10], Step [600/732], Loss: 0.5288\n",
      "Folder [8/10], Epoch [6/10], Step [700/732], Loss: 0.7028\n",
      "Folder [8/10], Epoch [7/10], Step [0/732], Loss: 0.2561\n",
      "Folder [8/10], Epoch [7/10], Step [100/732], Loss: 0.5064\n",
      "Folder [8/10], Epoch [7/10], Step [200/732], Loss: 0.6558\n",
      "Folder [8/10], Epoch [7/10], Step [300/732], Loss: 0.5647\n",
      "Folder [8/10], Epoch [7/10], Step [400/732], Loss: 0.7465\n",
      "Folder [8/10], Epoch [7/10], Step [500/732], Loss: 0.7962\n",
      "Folder [8/10], Epoch [7/10], Step [600/732], Loss: 0.5167\n",
      "Folder [8/10], Epoch [7/10], Step [700/732], Loss: 0.6981\n",
      "Folder [8/10], Epoch [8/10], Step [0/732], Loss: 0.2597\n",
      "Folder [8/10], Epoch [8/10], Step [100/732], Loss: 0.5116\n",
      "Folder [8/10], Epoch [8/10], Step [200/732], Loss: 0.6457\n",
      "Folder [8/10], Epoch [8/10], Step [300/732], Loss: 0.5659\n",
      "Folder [8/10], Epoch [8/10], Step [400/732], Loss: 0.7350\n",
      "Folder [8/10], Epoch [8/10], Step [500/732], Loss: 0.7892\n",
      "Folder [8/10], Epoch [8/10], Step [600/732], Loss: 0.5164\n",
      "Folder [8/10], Epoch [8/10], Step [700/732], Loss: 0.6930\n",
      "Folder [8/10], Epoch [9/10], Step [0/732], Loss: 0.2588\n",
      "Folder [8/10], Epoch [9/10], Step [100/732], Loss: 0.5082\n",
      "Folder [8/10], Epoch [9/10], Step [200/732], Loss: 0.6461\n",
      "Folder [8/10], Epoch [9/10], Step [300/732], Loss: 0.5651\n",
      "Folder [8/10], Epoch [9/10], Step [400/732], Loss: 0.7353\n",
      "Folder [8/10], Epoch [9/10], Step [500/732], Loss: 0.7797\n",
      "Folder [8/10], Epoch [9/10], Step [600/732], Loss: 0.5102\n",
      "Folder [8/10], Epoch [9/10], Step [700/732], Loss: 0.6833\n",
      "Folder [8/10], Epoch [10/10], Step [0/732], Loss: 0.2595\n",
      "Folder [8/10], Epoch [10/10], Step [100/732], Loss: 0.5052\n",
      "Folder [8/10], Epoch [10/10], Step [200/732], Loss: 0.6348\n",
      "Folder [8/10], Epoch [10/10], Step [300/732], Loss: 0.5587\n",
      "Folder [8/10], Epoch [10/10], Step [400/732], Loss: 0.7352\n",
      "Folder [8/10], Epoch [10/10], Step [500/732], Loss: 0.7723\n",
      "Folder [8/10], Epoch [10/10], Step [600/732], Loss: 0.5090\n",
      "Folder [8/10], Epoch [10/10], Step [700/732], Loss: 0.6790\n",
      "Training on folder: split_9\n",
      "Folder [9/10], Epoch [1/10], Step [0/733], Loss: 0.6578\n",
      "Folder [9/10], Epoch [1/10], Step [100/733], Loss: 0.6539\n",
      "Folder [9/10], Epoch [1/10], Step [200/733], Loss: 1.1559\n",
      "Folder [9/10], Epoch [1/10], Step [300/733], Loss: 1.0911\n",
      "Folder [9/10], Epoch [1/10], Step [400/733], Loss: 0.4264\n",
      "Folder [9/10], Epoch [1/10], Step [500/733], Loss: 0.9371\n",
      "Folder [9/10], Epoch [1/10], Step [600/733], Loss: 0.8509\n",
      "Folder [9/10], Epoch [1/10], Step [700/733], Loss: 1.2191\n",
      "Folder [9/10], Epoch [2/10], Step [0/733], Loss: 0.6156\n",
      "Folder [9/10], Epoch [2/10], Step [100/733], Loss: 0.6274\n",
      "Folder [9/10], Epoch [2/10], Step [200/733], Loss: 1.0709\n",
      "Folder [9/10], Epoch [2/10], Step [300/733], Loss: 1.0135\n",
      "Folder [9/10], Epoch [2/10], Step [400/733], Loss: 0.4132\n",
      "Folder [9/10], Epoch [2/10], Step [500/733], Loss: 0.8864\n",
      "Folder [9/10], Epoch [2/10], Step [600/733], Loss: 0.8195\n",
      "Folder [9/10], Epoch [2/10], Step [700/733], Loss: 1.1479\n",
      "Folder [9/10], Epoch [3/10], Step [0/733], Loss: 0.5933\n",
      "Folder [9/10], Epoch [3/10], Step [100/733], Loss: 0.6105\n",
      "Folder [9/10], Epoch [3/10], Step [200/733], Loss: 1.0260\n",
      "Folder [9/10], Epoch [3/10], Step [300/733], Loss: 0.9687\n",
      "Folder [9/10], Epoch [3/10], Step [400/733], Loss: 0.4052\n",
      "Folder [9/10], Epoch [3/10], Step [500/733], Loss: 0.8613\n",
      "Folder [9/10], Epoch [3/10], Step [600/733], Loss: 0.8005\n",
      "Folder [9/10], Epoch [3/10], Step [700/733], Loss: 1.1029\n",
      "Folder [9/10], Epoch [4/10], Step [0/733], Loss: 0.5827\n",
      "Folder [9/10], Epoch [4/10], Step [100/733], Loss: 0.5989\n",
      "Folder [9/10], Epoch [4/10], Step [200/733], Loss: 0.9957\n",
      "Folder [9/10], Epoch [4/10], Step [300/733], Loss: 0.9451\n",
      "Folder [9/10], Epoch [4/10], Step [400/733], Loss: 0.4025\n",
      "Folder [9/10], Epoch [4/10], Step [500/733], Loss: 0.8451\n",
      "Folder [9/10], Epoch [4/10], Step [600/733], Loss: 0.7862\n",
      "Folder [9/10], Epoch [4/10], Step [700/733], Loss: 1.0681\n",
      "Folder [9/10], Epoch [5/10], Step [0/733], Loss: 0.5693\n",
      "Folder [9/10], Epoch [5/10], Step [100/733], Loss: 0.5889\n",
      "Folder [9/10], Epoch [5/10], Step [200/733], Loss: 0.9775\n",
      "Folder [9/10], Epoch [5/10], Step [300/733], Loss: 0.9230\n",
      "Folder [9/10], Epoch [5/10], Step [400/733], Loss: 0.3978\n",
      "Folder [9/10], Epoch [5/10], Step [500/733], Loss: 0.8316\n",
      "Folder [9/10], Epoch [5/10], Step [600/733], Loss: 0.7728\n",
      "Folder [9/10], Epoch [5/10], Step [700/733], Loss: 1.0354\n",
      "Folder [9/10], Epoch [6/10], Step [0/733], Loss: 0.5642\n",
      "Folder [9/10], Epoch [6/10], Step [100/733], Loss: 0.5783\n",
      "Folder [9/10], Epoch [6/10], Step [200/733], Loss: 0.9533\n",
      "Folder [9/10], Epoch [6/10], Step [300/733], Loss: 0.8987\n",
      "Folder [9/10], Epoch [6/10], Step [400/733], Loss: 0.3956\n",
      "Folder [9/10], Epoch [6/10], Step [500/733], Loss: 0.8135\n",
      "Folder [9/10], Epoch [6/10], Step [600/733], Loss: 0.7640\n",
      "Folder [9/10], Epoch [6/10], Step [700/733], Loss: 1.0034\n",
      "Folder [9/10], Epoch [7/10], Step [0/733], Loss: 0.5587\n",
      "Folder [9/10], Epoch [7/10], Step [100/733], Loss: 0.5731\n",
      "Folder [9/10], Epoch [7/10], Step [200/733], Loss: 0.9359\n",
      "Folder [9/10], Epoch [7/10], Step [300/733], Loss: 0.8827\n",
      "Folder [9/10], Epoch [7/10], Step [400/733], Loss: 0.3976\n",
      "Folder [9/10], Epoch [7/10], Step [500/733], Loss: 0.8006\n",
      "Folder [9/10], Epoch [7/10], Step [600/733], Loss: 0.7557\n",
      "Folder [9/10], Epoch [7/10], Step [700/733], Loss: 0.9936\n",
      "Folder [9/10], Epoch [8/10], Step [0/733], Loss: 0.5523\n",
      "Folder [9/10], Epoch [8/10], Step [100/733], Loss: 0.5688\n",
      "Folder [9/10], Epoch [8/10], Step [200/733], Loss: 0.9333\n",
      "Folder [9/10], Epoch [8/10], Step [300/733], Loss: 0.8642\n",
      "Folder [9/10], Epoch [8/10], Step [400/733], Loss: 0.3874\n",
      "Folder [9/10], Epoch [8/10], Step [500/733], Loss: 0.7927\n",
      "Folder [9/10], Epoch [8/10], Step [600/733], Loss: 0.7481\n",
      "Folder [9/10], Epoch [8/10], Step [700/733], Loss: 0.9739\n",
      "Folder [9/10], Epoch [9/10], Step [0/733], Loss: 0.5435\n",
      "Folder [9/10], Epoch [9/10], Step [100/733], Loss: 0.5612\n",
      "Folder [9/10], Epoch [9/10], Step [200/733], Loss: 0.9252\n",
      "Folder [9/10], Epoch [9/10], Step [300/733], Loss: 0.8429\n",
      "Folder [9/10], Epoch [9/10], Step [400/733], Loss: 0.3881\n",
      "Folder [9/10], Epoch [9/10], Step [500/733], Loss: 0.7956\n",
      "Folder [9/10], Epoch [9/10], Step [600/733], Loss: 0.7411\n",
      "Folder [9/10], Epoch [9/10], Step [700/733], Loss: 0.9549\n",
      "Folder [9/10], Epoch [10/10], Step [0/733], Loss: 0.5380\n",
      "Folder [9/10], Epoch [10/10], Step [100/733], Loss: 0.5590\n",
      "Folder [9/10], Epoch [10/10], Step [200/733], Loss: 0.9049\n",
      "Folder [9/10], Epoch [10/10], Step [300/733], Loss: 0.8276\n",
      "Folder [9/10], Epoch [10/10], Step [400/733], Loss: 0.3896\n",
      "Folder [9/10], Epoch [10/10], Step [500/733], Loss: 0.7780\n",
      "Folder [9/10], Epoch [10/10], Step [600/733], Loss: 0.7311\n",
      "Folder [9/10], Epoch [10/10], Step [700/733], Loss: 0.9375\n",
      "Training on folder: split_10\n",
      "Folder [10/10], Epoch [1/10], Step [0/733], Loss: 0.7876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[1;32m---> 65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformulas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformulas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformulas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mformulas\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m, in \u001b[0;36mLaTeXDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[0;32m     32\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_folder, image_name)\n\u001b[1;32m---> 33\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m     35\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embed_size = 128\n",
    "hidden_size = 512\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((50, 400)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset and dataloader\n",
    "\n",
    "\n",
    "dataset = LaTeXDataset(\"LaTex_data/split_1\" , mapping_path, label_to_index_path, transform)\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, dataset.vocab_size)\n",
    "model = ImageToLaTeXModel(encoder, decoder)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=1)  # 0 is assumed as <PAD> token\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "start_epoch = 0\n",
    "\n",
    "# Define the paths of your image folders\n",
    "folders = [\"split_1\", \"split_2\", \"split_3\", \"split_4\", \"split_5\", \n",
    "           \"split_6\", \"split_7\", \"split_8\", \"split_9\", \"split_10\"]\n",
    "\n",
    "# Function to save model state\n",
    "def save_training_state(model, optimizer, epoch, folder_idx, loss):\n",
    "    state = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'folder_idx': folder_idx,\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(state, 'model_checkpoint.pth')\n",
    "\n",
    "# Function to load model state\n",
    "def load_training_state(model, optimizer):\n",
    "    checkpoint = torch.load('model_checkpoint.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return checkpoint['epoch'], checkpoint['folder_idx'], checkpoint['loss']\n",
    "\n",
    "# Try to resume from a checkpoint\n",
    "try:\n",
    "    start_epoch, start_folder_idx, last_loss = load_training_state(model, optimizer)\n",
    "    print(f\"Resuming training from folder {start_folder_idx+1}, epoch {start_epoch}, with loss {last_loss:.4f}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No saved model found, starting fresh.\")\n",
    "    start_epoch = 0\n",
    "    start_folder_idx = 0\n",
    "\n",
    "# Training loop\n",
    "for folder_idx in range(start_folder_idx, len(folders)):\n",
    "    print(f\"Training on folder: {folders[folder_idx]}\")\n",
    "    dataset = LaTeXDataset(\"LaTex_data/\" + folders[folder_idx], mapping_path, label_to_index_path, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        for i, (images, formulas) in enumerate(dataloader):\n",
    "            images, formulas = images.to(device), formulas.to(device)\n",
    "            targets = formulas[:, 1:]\n",
    "\n",
    "            outputs = model(images, formulas[:, :-1])\n",
    "            loss = criterion(outputs.view(-1, dataset.vocab_size), targets.contiguous().view(-1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Folder [{folder_idx+1}/{len(folders)}], Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "            # Save model periodically and at the end of each folder\n",
    "            if i % 200 == 0 or (i == len(dataloader) - 1):\n",
    "                save_training_state(model, optimizer, epoch, folder_idx, loss.item())\n",
    "        \n",
    "        # Reset start_epoch for next folder\n",
    "        start_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Formula: _ { a } \\left( z \\right) = \\int _ { 0 } ^ { \\infty } \\mathrm { d } t \\, \\mathrm { c o s h } \\left( a \\, t \\right) \\mathrm { e } ^ { - z \\, \\mathrm { c o s h } \\left( t \\right) } ,\n",
      "Predicted Formula: { \\mu } ( x \\right) = \\int _ { 0 } ^ { \\infty } d z d } z { { ^ e } } s } \\left( \\left( ^ { \\right) ^ { e } ^ { - i _ { { e } } s } } \\right) \\right)\n",
      "--------------------------------------------------\n",
      "Actual Formula: [ A ] = { \\frac { k } { 4 \\pi } } \\int _ { \\Sigma } \\mathrm { T r } \\left[ A \\wedge d A + \\frac { 2 } { 3 } A \\wedge A \\wedge A \\right]\n",
      "Predicted Formula: { ] = \\int _ { 1 } { 4 \\pi } } \\int d ^ \\Sigma } d ^ d } } [ A ^ { + + + A 1 } } 4 } A { { \\wedge { \\right] ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { Q } = \\int d ^ { 2 } x \\, [ - \\nabla ^ { m } \\phi _ { + } \\nabla _ { m } \\phi _ { + } + \\nabla ^ { m } \\phi _ { - } \\nabla _ { m } \\phi _ { - } - m ^ { 2 } ( \\phi _ { + } + \\phi _ { - } ) ^ { 2 } ] .\n",
      "Predicted Formula: \\int \\mathrm } = \\int d ^ { 4 } x \\sqrt { { { { { 2 } \\phi _ { m } \\partial { { + } \\phi + { + } + { _ { 2 } \\phi _ { + } + + { + } \\phi + { + } + \\frac _ { 2 } \\phi _ _ { + } \\phi _ _ { + } ) ) ] 2 } ] .\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\ \\ \\dot { A } } ^ { C } \\overline { { R } } = 6 \\alpha \\left( \\nabla _ { \\ \\ \\dot { A } } ^ { C } W ^ { 2 } \\right) \\overline { { \\nabla } } ^ { 2 } \\overline { { W } } ^ { 2 } + 6 \\alpha W ^ { 2 } \\overline { { \\nabla } } ^ { 2 } \\nabla _ { \\ \\ \\dot { A } } ^ { C } \\overline { { W } } ^ { 2 } + { \\cal O } \\left( \\alpha ^ { 2 } \\right)\n",
      "Predicted Formula: { \\alpha } } } A } } ^ { i } } _ { } } } ^ { \\ ^ { _ \\right) c } c } A } } ^ { i } } ^ { A { + \\dot { { C } } ^ { \\dot } \\ _ { } } } _ { \\dot } \\ \\overline _ ^ { { 2 } \\ \\overline { C } } ^ { 2 } + \\overline { \\overline { { { A } } ^ { 2 } } { { } } } ^ { \\dot } } \\ ^ { } ( \\overline \\right) { 2 } \\right) \\ \\\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( { \\phi } ) = { M ^ { - 2 } } _ { P l } \\int { \\frac { V } { V ^ { \\prime } } d { \\phi } }\n",
      "Predicted Formula: { , { ) = \\int _ { { 2 } } } _ { 0 } } \\int { { { d ^ { d } { \\ast } } } d } } } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\alpha _ { m } ^ { \\mu } , \\alpha _ { n } ^ { \\nu } ] = m \\delta _ { m , - n } \\eta ^ { \\mu \\nu } .\n",
      "Predicted Formula: _ { n } ^ { \\alpha } , \\alpha _ { n } ^ { \\nu } ] = i _ { { n } n } } \\delta _ { \\mu \\nu }\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 1 } = q _ { 2 } = q _ { 3 } + q _ { 4 } = 2 \\ell \\; , \\quad J = 0 \\; .\n",
      "Predicted Formula: { 1 } = q , { 1 } + q _ { 1 } = q _ { 3 } = 0 _ _ { _ \\ell _ { , \\quad \\quad\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) \\, \\xi _ { \\bf p } ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) = p _ { 0 } \\, \\xi _ { \\bf p } ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) , \\quad { \\bf P } ^ { ( 0 ) } ( { \\alpha } , { \\bf n ) } \\, { \\xi } _ { \\bf p } ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) = { \\bf p } \\, { \\xi } _ { \\bf p } ^ { ( 0 ) } ( { \\alpha } , { \\bf n } ) .\n",
      "Predicted Formula: { 2 } ) } ( { , x , { , } } ) = \\alpha \\, { n } } ( \\xi \\dagger 0 ) } ( \\xi , p , { \\bf n } ) = - _ { 0 } } { _ { 0 } } ^ { ( 0 ) } ( { \\bf p , { \\bf } } ) + _ _ _ } } _ { ( } ) } ( { , p _ { \\bf n } , = { _ } _ { n } } ^ { ( 0 ) } ( { \\bf p , { \\bf p } ) = - _ n } _ { _ \\xi _ { ( 0 } ^ { \\dagger 0 ) } ( { \\bf p , { \\bf } } ) \\,\n",
      "--------------------------------------------------\n",
      "Actual Formula: { \\rho } ( r ; x ) = \\frac { \\partial } { \\partial x } \\rho ( r ; x ) .\n",
      "Predicted Formula: A } = { ) = ) = \\frac { 1 } } \\partial x } { { x ) x ) ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { 1 } ( d P _ { 9 } , { \\cal { O } } _ { d P _ { 9 } } ( 9 \\sigma | _ { d P _ { 9 } } - F ) ) | _ { c _ { - 3 } } = 2 .\n",
      "Predicted Formula: { \\mu } 2 _ , ^ { 9 } , { \\cal O } } } _ { 9 } ^ { 9 } } ( X \\sigma ^ { { d P _ { 9 } } + d ) { = { d _ { - } } } } =\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 5 } ^ { \\mu \\nu } = - i e ^ { 2 } M _ { 5 } ^ { \\mu \\nu } ,\n",
      "Predicted Formula: { i } ^ { \\mu } = = - _ ^ ^ { \\mu } } _ { \\mu \\nu ^ { \\mu } } ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 1 , 2 } \\times \\Phi _ { 1 , 2 } = \\Phi _ { 1 , 1 } + \\Phi _ { 1 , 3 }\n",
      "Predicted Formula: { i } = } = { _ { 1 , 2 } = { _ { 1 , 2 } + \\Phi _ { 2 , 2 } +\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\begin{array} { l } { x ^ { \\prime } = D ( \\Lambda , u ) x } \\\\ { u ^ { \\prime } = D ( \\Lambda , u ) u } \\\\ \\end{array} \\right.\n",
      "Predicted Formula: { r c l E _ { 2 } = x ^ x ) x ) = } { { x ^ { \\prime } = x ^ { ) u ^ { } \\\\ \\end{array} \\right.\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( D _ { i \\alpha } W _ { ~ \\gamma } ^ { \\beta } - \\delta _ { \\alpha } ^ { ~ \\beta } D _ { i \\gamma } W _ { ~ \\delta } ^ { \\delta } ) = D _ { i \\delta } W _ { ~ \\{ \\alpha } ^ { \\delta } \\delta _ { ~ \\gamma \\} } ^ { \\beta } - D _ { i \\{ \\alpha } W _ { ~ \\gamma \\} } ^ { \\beta } - 3 D _ { i \\{ \\alpha } \\delta _ { ~ \\gamma \\} } ^ { \\beta } W _ { ~ \\delta } ^ { \\delta }\n",
      "Predicted Formula: _ _ 1 1 } } } { { i i } ^ { i } + = _ { i \\beta } { i } } } _ { \\beta } } } { { \\beta \\beta } ^ { i } } = - _ { i \\beta } D _ { ~ \\beta } _ { { i } } = { i \\beta } ^ ^ { i } = ~ _ { i \\beta } \\gamma } { { ~ i { } ^ { i } } { \\frac _ { i \\beta } \\} } { { \\alpha \\beta } ^ ^ { i } } { ~ i ~ } { i \\beta }\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { A } = c ^ { A \\alpha } Z ^ { \\alpha } , \\; \\; F _ { A } = c ^ { A \\alpha } \\omega _ { \\alpha \\beta } Z ^ { \\beta } .\n",
      "Predicted Formula: { i } = X _ { A } X + _ { A A } A ^ \\; \\; { A } = { ^ { A } } } ^ { A } } { A A }\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { p h } ( t ) = \\Lambda _ { 0 } - \\frac { m _ { F } ^ { 4 } \\, \\, U ^ { 2 } ( t ) } { 2 f ( t ) } + \\frac { 2 \\, m _ { F } ^ { 4 } } { ( 4 \\pi ) ^ { 2 } } \\; \\int _ { 0 } ^ { t } U ^ { 2 } ( t ) d t - \\frac { 2 } { ( 4 \\pi ) ^ { 2 } } \\, \\sum _ { i } \\, N _ { i } \\int _ { o } ^ { t } m _ { i } ^ { 4 } ( t ) \\, d t \\, ,\n",
      "Predicted Formula: { n } ( ^ { ) = \\int _ { 0 } ^ { { 1 } { 0 } } { 2 } } { { { { \\prime } } { ) } { 4 } } { ) } \\left[ ^ { 1 } } _ { f } ^ { 2 } } { 4 _ \\pi _ ) { 4 } } \\, { _ { 0 } ^ { \\infty } d ^ { 2 } d ^ ) \\, ^ \\; { _ 1 } } 4 } - ) ) { 4 } } } ^ ^ { m = 1 _ _ { i } ^ { { 0 } ^ { t } d _ { i } ^ { 2 } \\, t ) \\, ^ ^ { { t\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 2 } : = \\{ y _ { 2 } = 0 \\} \\cong { \\mathbb P } ^ { 2 } ( x ) ,\n",
      "Predicted Formula: { \\alpha } ( { { _ _ { 1 } , { { + { _ { } ^ { 2 } = _ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { B _ { 2 } } \\left( \\kappa _ { 2 } \\, u _ { \\mu \\nu } ^ { 0 } ( x ) T ^ { \\mu \\nu } + \\kappa _ { 2 } \\sum _ { n = 1 } ^ { \\infty } \\frac { \\psi _ { n } ( R ) e ^ { 2 k R } } { N _ { 0 } } \\, u _ { \\mu \\nu } ^ { n } ( x ) T ^ { \\mu \\nu } - \\frac { \\kappa _ { 1 } } { \\sqrt { 3 } } \\varphi \\, T _ { \\mu } ^ { \\mu } \\right) d z .\n",
      "Predicted Formula: { 0 } { 2 } } { ^ _ { 1 } ^ { _ { 2 } \\right) \\right) { ( } } _ ) { _ { \\mu \\nu } ( x _ { \\mu } ^ { { \\mu = 0 } ^ { \\infty } \\int _ d } { \\mu } ^ { ) } { { - } } } } { 2 } { n } ^ { _ _ { n } ( ( x ( } ( x ) R _ { \\mu \\nu } ( x _ 1 } { n } ^ { 2 } 2 } } T _ { _ { \\mu \\nu } { \\nu } } x { _ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mathrm { T } } ( s ) = \\sum _ { m = - \\infty } ^ { \\infty } \\sum _ { \\{ k \\} } \\left( \\Omega _ { m } ^ { 2 } + \\omega _ { k } ^ { 2 } \\right) ^ { - s } { , }\n",
      "Predicted Formula: { 0 } s } } ( { ) = \\sum _ { n = 0 \\infty } ^ { \\infty } \\frac _ { m = _ { m _ { { m m } { ( k - { _ { k } ^ { 2 } \\right) ^ { 2 } } , , }\n",
      "--------------------------------------------------\n",
      "Actual Formula: F , G ] ( { \\bf x , y } ) = \\int { d ^ { 3 } z \\: [ F ( { \\bf x , z } ) G ( { \\bf z , y } ) - G ( { \\bf x , z } ) F ( { \\bf z , y } ) ] } .\n",
      "Predicted Formula: _ { ] = { ) { } , } ) = \\int { { { { 3 } x \\bf { { \\bf { , x } , ) ) - ( x , x } , } ) + G { { , x } , y ) - ( { , x } ] ] ) ] ]\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\cal W } = h \\left( Q ^ { 1 } Q ^ { 2 } Q ^ { 3 } + Q ^ { 4 } Q ^ { 5 } Q ^ { 6 } + Q ^ { 7 } Q ^ { 8 } Q ^ { 9 } + \\tilde { Q } _ { 1 } \\tilde { Q } _ { 2 } \\tilde { Q } _ { 3 } + \\tilde { Q } _ { 4 } \\tilde { Q } _ { 5 } \\tilde { Q } _ { 6 } + \\tilde { Q } _ { 7 } \\tilde { Q } _ { 8 } \\tilde { Q } _ { 9 } \\right) \\, ,\n",
      "Predicted Formula: L } _ { { { _ { 2 } + + { 1 } + Q { 2 } + ^ ^ { 2 } \\right) ^ { 2 } \\right) + { 2 } + + ^ { 2 } h ^ { 6 } \\right) + { 6 } \\right) + ^ Q } ^ { 5 } ^ { Q } _ { 2 } + { Q } _ { 2 } + { { Q } _ { 6 } \\tilde { Q } _ { 6 } + { h } _ { 6 } + { { \\cal } _ { 6 } \\tilde { Q } _ { 2 } \\right) { Q } _ { 6 } \\right) {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mathrm { e f f } } = V _ { \\mathrm { S U S Y } } ( y _ { i } ) + V _ { \\mathrm { S o f t } } ( y _ { i } ) + V _ { \\mathrm { Q u a r t i c } } ( y _ { i } ) .\n",
      "Predicted Formula: { \\mathrm } m a f } } ( { _ { \\mathrm } m r } } } } ( { ) + \\mathrm } ) + _ _ { \\mathrm } e a } } } } ( { _ { i } ) + _ _ { \\mathrm } e n } } } } } } } ( x _ { i } ) +\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { i } ^ { \\mathrm { d i m } ( T P ) ^ { \\mathrm { v e r t i c a l } } } C ^ { \\dagger } .\n",
      "Predicted Formula: { i } j { ( } \\tiny o v } } = ) } ) = 2 } \\scriptsize } } } } } } } } } = \\lambda _ { i } =\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\phi _ { k } \\, , \\, \\phi _ { h } ] = - { \\frac { i \\pi \\beta ^ { 2 } } { 2 } } s \\left( \\frac { k - h } { 2 N } \\right) \\quad , \\quad [ \\bar { \\phi } _ { k } \\, , \\, \\bar { \\phi } _ { h } ] = { \\frac { i \\pi \\beta ^ { 2 } } { 2 } } s \\left( \\frac { k - h } { 2 N } \\right) \\quad , \\quad [ \\phi _ { k } \\, , \\, \\bar { \\phi } _ { h } ] = 0 \\quad .\n",
      "Predicted Formula: ] { n } ( { \\, _ _ { k } ( = { \\, { { 1 } } { { 2 } } { 2 } } \\left( \\left( { - 1 } } } { 2 } + \\right) + , { \\left[ { _ h } _ { k } , = \\, { { h } _ { k } ] = - { { 1 } } { { 2 } } { 2 } } \\left[ { { \\frac 1 } { } { 2 } + \\right) + { { _ _ { k } , = { { { \\phi } _ { k } ] = 2 \\, ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { i } = \\zeta _ { i } - \\frac { \\sum _ { k } \\zeta _ { k } n _ { k } } { \\sum _ { l } n _ { l } } .\n",
      "Predicted Formula: { i } = { _ { i } + \\frac { \\lambda _ { i = 1 { { i } } { { i } } { ( _ { k = 1 _ { k } } { _\n",
      "--------------------------------------------------\n",
      "Actual Formula: = { \\bar { A } } ( u ) e x p \\bigg \\{ + \\int \\kappa s n u d u \\bigg \\} .\n",
      "Predicted Formula: { _ { \\pi } } _ { ) + \\int { ( \\int i { { { { \\} ~ \\} \\} ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mu } \\theta _ { m } ^ { \\mu } ( t ) = n _ { \\mu } { \\frac { \\partial L _ { ( m ) } } { \\partial \\nabla _ { \\mu } \\phi } } { \\cal L } _ { t } \\phi = - N { \\frac { \\partial L _ { ( m ) } } { \\partial \\dot { \\phi } } } { \\cal L } _ { t } \\phi ~ ~ ~ ,\n",
      "Predicted Formula: { H } ^ { { \\mu } ^ { \\mu } = - ) = \\sqrt _ { m } ^ { { \\partial ^ { { m } ) n } { \\partial t _ { m } } } { t ( L } _ { m } t { { , ( { { \\partial } { { m } ) } } { \\partial t } \\phi } _ { { } _ { m } t { { ~ ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\frac { 1 } { 2 } \\left( { p _ { x } } ^ { 2 } + { p _ { y } } ^ { 2 } + \\frac { x ^ { 2 } } { m ^ { 2 } } + \\frac { y ^ { 2 } } { n ^ { 2 } } \\right) ,\n",
      "Predicted Formula: { \\frac 1 } { 2 } \\left( { { { { 1 } ^ { { 2 } + \\frac { { { x } } ^ { 2 } + y { y } { 2 } } { y ^ { 2 } } \\right) y _ y } { 2 } } { 2 ^ { 2 } } \\right) .\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( { \\bf k } , t ) = b _ { \\mathrm { E } } ( 1 , { \\bf k } , t ) , \\qquad d ( { \\bf k } , t ) = b _ { \\mathrm { E } } ( - 1 ,\n",
      "Predicted Formula: { _ { } , { ) = { _ { 1 } t t } ( ( , t , k } ) \\, ) , _ { _ { \\bf k } , { ) = { _ { \\mathrm { c t } ( t , ) ^ )\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 4 } = \\frac { 3 D } { 2 } e ^ { - 2 \\phi } e ^ { 2 \\chi } c \\partial c { \\partial } ^ { 2 } c .\n",
      "Predicted Formula: { \\mu } = { { 1 } { { 2 } } ^ { - 2 { } + { { - \\phi } } \\frac { { } ^ { 2 } \\chi\n",
      "--------------------------------------------------\n",
      "Actual Formula: d ^ { 6 } z \\Phi ^ { 2 } \\Box \\Phi = \\frac { 1 } { 1 6 } \\int d ^ { 6 } z \\Phi ^ { 2 } \\bar { D } ^ { 2 } D ^ { 2 } \\Phi = - \\frac { 1 } { 4 } \\int d ^ { 8 } z \\Phi ^ { 2 } D ^ { 2 } \\Phi .\n",
      "Predicted Formula: { { 4 } x \\, { { i } = \\frac { \\int { 1 } { 2 } \\int } { { { 4 } z \\sqrt { { 2 } \\Phi ^ \\Phi } ^ { 2 } \\Phi { { 2 } \\Phi \\bar { { { 1 } { 4 } } { ^ { 4 } z \\bar { { 2 } \\, { { 2 } \\Phi\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { i } ^ { 2 } = \\frac { 1 } { 4 } b _ { i } - \\frac { 1 } { 2 4 } \\sum _ { j } b _ { j } ,\n",
      "Predicted Formula: { 1 } = \\sum 2 } = \\frac _ 1 } { 2 } } _ { i } ^ { { 1 } { 2 } \\sum \\sum _ { i = 1 _ { j } ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { - ^ { \\prime } } = \\frac { { \\bf x } ^ { 2 } } 2 , \\quad p ^ { - ^ { \\prime } } = \\left( { \\bf x } \\cdot { \\bf p } - x ^ { - } p ^ { + } \\right) , \\quad p ^ { - } = \\frac { { \\bf p } ^ { 2 } } { 2 p ^ { + } } .\n",
      "Predicted Formula: { 2 } = \\prime } } = \\frac \\frac 1 } ^ } ^ { 2 } } { 2 ^ x ^ { 2 } } \\prime } } = x { ^ x } { { \\bf x } \\right) { \\right) { \\prime } \\right) \\right) { - } \\right) \\right) { \\quad ^ { - } = \\frac x x } ^ } ^ { \\prime } } { 2 ^ ^ { 2 } } , \\quad\n",
      "--------------------------------------------------\n",
      "Actual Formula: U ( t ) f ) ( x ) = \\int _ { M } d y \\, K ( x , y ; t ) f ( y )\n",
      "Predicted Formula: _ { ) t t { { ) = \\int _ { x } d ^ { { ( { , y ) t ) \\, { y ) \\,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mu \\nu } \\rightarrow \\tilde { G } _ { \\mu \\nu } = \\frac { 1 } { 2 } e ^ { - 2 \\phi } \\epsilon _ { \\mu \\nu \\rho \\sigma } G ^ { \\rho \\sigma } , \\, \\phi \\rightarrow - \\phi ,\n",
      "Predicted Formula: { \\mu \\nu } = \\frac _ G } _ { \\mu \\nu } - { { 1 } { 2 } g _ { - } } } { _ { \\mu \\nu \\rho } } { ^ { \\sigma \\sigma } } _ { ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { H } \\equiv { \\frac { 2 } { f ^ { \\prime } ( r _ { + } ) } } = { \\frac { r _ { + } l ^ { 2 } } { r _ { + } ^ { 2 } + | r _ { - } | ^ { 2 } } }\n",
      "Predicted Formula: { 1 } = { { { 1 } { \\sqrt { { 2 } } } ) } H } ) } } = { { { 1 } { + } ^ { { 2 } } { r r { + } ^ { 2 } + } _ { { + } | { { 2 } } } ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { A } ^ { M } ( g ) = L _ { A } ^ { M } ( g h , h ) | _ { h = e } \\, , \\quad \\overline { { L } } _ { M } ^ { A } ( g ) = \\overline { { L } } _ { M } ^ { A } ( h , g h ) | _ { h = e } \\, ,\n",
      "Predicted Formula: { 0 } } { ( } ( { , = { _ { A } ^ { M } ( _ ) { { ) { A _ M = 0 } = - \\, h _ { g } } _ { g } ^ { A } ( g , \\overline _ _ { g } } _ { A } ^ { A } ( g , g ) { { _ _ h = ^ } } g\n",
      "--------------------------------------------------\n",
      "Actual Formula: { \\rho ( t ) = \\ut _ { ( 2 ) } \\rho S ( \\ut _ { ( 1 ) } ) } .\n",
      "Predicted Formula: _ { { _ { { _ { 0 } ) } ^ t { { ) t 0 } ) } } + { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 0 } ^ { 2 \\pi } d x ^ { \\prime } \\, K _ { S ^ { 1 } } ^ { \\omega } ( x ^ { \\prime \\prime } , x ^ { \\prime } ; t ^ { \\prime } ) \\, K _ { S ^ { 1 } } ^ { \\omega } ( x ^ { \\prime } , x ; t ) = K _ { S ^ { 1 } } ^ { \\omega } ( x ^ { \\prime \\prime } , x ; t + t ^ { \\prime } )\n",
      "Predicted Formula: { 0 } ^ { \\infty } } d { \\, ^ \\prime } \\, { _ { ( } ( \\prime } } ^ x \\prime } ( x ^ { \\prime } , , x ^ { \\prime } ) \\delta ) { \\prime } ) \\delta _ ^ { 1 } } \\prime } } ( x \\prime } ( x ^ { \\prime } , x ^ { ^ { ^ ^ { 1 } ^ \\prime } } ^ { \\prime } ( x ^ { \\prime } , , x ^ { ) { ) { \\prime } )\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { r } = = - \\frac a { r ^ { 2 } + a ^ { 2 } } I _ { \\phi } .\n",
      "Predicted Formula: { n } = { { { { 1 | r { 2 } } \\frac } { 2 } } \\, { r } ^\n",
      "--------------------------------------------------\n",
      "Actual Formula: n ^ { A } = \\frac { d \\phi ^ { A } } { | | \\phi | | } + \\phi ^ { A } d \\left( \\frac 1 { | | \\phi | | } \\right) ,\n",
      "Predicted Formula: ^ { 2 } = \\frac { 1 } } { i } } { d \\phi | _ { { { { { { A } } \\frac { \\frac \\phi | | | ^ { { { \\right)\n",
      "--------------------------------------------------\n",
      "Actual Formula: j _ { \\mu } ( x _ { 1 } ) j _ { \\nu } ( x _ { 2 } ) \\rangle , \\qquad \\langle T _ { \\mu \\nu } ( x _ { 1 } ) T _ { \\rho \\sigma } ( x _ { 2 } ) \\rangle\n",
      "Predicted Formula: _ { \\mu } ( x ) { \\mu } ) x _ { 2 } ( x _ { 2 } ) \\rangle _ { _ _ _ { \\mu \\nu } ( x _ { 1 } ) x _ { \\mu } ( ( x _ { 2 } ) \\rangle = {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { ~ b } ^ { a } ( z ) = \\displaystyle { \\delta _ { ~ b } ^ { a } + 4 i \\frac { 1 } { x _ { - } ^ { 2 } } \\theta ^ { a } x _ { - } { \\cdot \\sigma } \\bar { \\theta } _ { b } }\n",
      "Predicted Formula: { 0 } } ^ { a } ( x ) = \\frac { { { { a b } ^ { a } ( z _ ^ _ z z { z z { 1 } ^ { 2 } } z _ { - } } _ { + } ^ { { } { z } _ { - } ^ { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 1 2 } = \\left( \\frac { i \\hbar } { 2 } \\right) \\sum _ { i = 1 } ^ { m } \\left( \\frac { \\partial } { \\partial q _ { 1 } ^ { i } } \\frac { \\partial } { \\partial p _ { 2 } ^ { i } } - \\frac { \\partial } { \\partial p _ { 1 } ^ { i } } \\frac { \\partial } { \\partial q _ { 2 } ^ { i } } \\right) .\n",
      "Predicted Formula: { \\mathrm } } = { { { 1 } } { 2 } } { { { k = 1 } ^ { N } \\frac { { \\partial _ { \\partial x _ { i } } + 2 } } + _ \\partial q { \\partial q _ { i } ^ { 2 } } \\right) \\frac { \\partial } { \\partial q _ { i } ^ { 2 } } \\frac \\frac \\partial } { \\partial q _ { i } ^ { 2 } } \\right) \\frac\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mu \\nu } ( x ) = h _ { \\mu \\nu } ^ { ( m ) } ( x ) + \\frac { 2 } { \\ell } \\, \\eta _ { \\mu \\nu } \\, \\hat { \\xi } \\, ^ { 5 } ( x ) \\, ,\n",
      "Predicted Formula: { \\mu } } ( x ) = \\frac { { \\mu \\nu } ^ { ( } ) } ( x ) + \\frac _ 1 } } 2 } { _ _ { \\mu \\nu } ( x ^ x } ^ { ( } \\, ) \\,\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\bf L } = - \\int R ^ { 2 } d \\Omega \\, \\biggl \\{ \\dot { f } \\, ( { \\bf r } \\times \\nabla ) f + f ^ { 2 } \\, ( \\dot { \\theta } + A _ { 0 } ) \\, { \\bf r } \\times ( \\nabla \\theta + { \\bf A } ) - \\rho _ { e } \\, { \\bf r } \\, ( { \\bf r } \\cdot \\nabla \\times { \\bf A } ) \\biggr \\} .\n",
      "Predicted Formula: L } _ { _ { { { 2 } ( { \\bf { ^ G ^ \\bf } + { { { { } - { \\bf { { { { { 2 } ( { { \\bf f } + { { { 0 } ) { { _ A } + { { \\bf { ^ { A } ) { { { { 0 } f { { A } \\times { { + r } - { \\bf ) \\bf A } ) + \\} +\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\frac { 1 } { \\sqrt { 2 } } \\Big ( ( 1 + \\gamma _ { 5 } ) \\psi + ( 1 - \\gamma _ { 5 } ) \\tilde { \\psi } \\Big ) .\n",
      "Predicted Formula: { { 1 } { \\sqrt } 2 } } \\left( \\left( 1 _ - \\sqrt { 1 1 } + \\gamma ) { { + \\gamma _ { 5 } ) ) ) \\psi } ) ) . ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { ( 1 ) } = - l _ { 0 } ^ { 2 } K _ { a } ^ { b } K _ { b } ^ { a } .\n",
      "Predicted Formula: { i } ) } = _ _ ^ { 1 } ^ { ( } e ^ { 0 } ^ { ( } } _ { a } ^ { ( }\n",
      "--------------------------------------------------\n",
      "Actual Formula: { n T _ { 0 } ^ { 3 } } { g _ { \\mathrm { e f f } } } = \\frac { T _ { 0 } ^ { 3 } } { g } \\sqrt { n ^ { 2 } + q ^ { 2 } + g ^ { 2 } \\, ( p - \\chi _ { 0 } q ) ^ { 2 } } \\, \\left( 1 + q ^ { 2 } / n ^ { 2 } \\right) ^ { - 1 } .\n",
      "Predicted Formula: 1 } { { 0 } } { 2 } } { 2 } { 0 } Y f f } } ^ = \\sqrt { 1 } { 0 } ^ { 2 } } { 4 4 { 4 g g { 2 } + g ^ { 2 } + ( ^ { 2 } ( ^ ^ ^ { ) { 0 } ) ^ { { 2 } + \\, \\chi ^ + \\frac { { 2 } \\chi \\chi \\right) { 2 } \\right) . { 1 } } 2 .\n",
      "--------------------------------------------------\n",
      "Actual Formula: { \\mit \\Omega } = - S \\delta \\Theta - { \\cal P } _ { i } \\, \\delta v ^ { i } \\ , \\qquad \\delta F = - S \\delta \\Theta + v ^ { i } \\delta { \\cal P } _ { i } \\ , \\qquad \\delta U = \\Theta \\delta S + v ^ { i } \\delta { \\cal P } _ { i } \\ .\n",
      "Predicted Formula: { D } { \\delta ^ ^ { + { _ { } _ { 1 } \\tiny { \\, { { i } \\, } \\ \\ _ { { \\, ^ { ^ { { { i } { { { R } _ { i } + { \\ ^ { { { { { { _ { i } { { { R } _ { i } \\,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 1 } ( x ) \\to \\sqrt { { \\frac { \\pi } { 2 x } } } e ^ { - x } ( 1 + { \\frac { 3 } { 8 x } } + \\cdots ) ,\n",
      "Predicted Formula: { 0 } ( x ) = \\frac { \\frac { { x } { 2 } } } } ^ { { - \\frac { { { - x { { 1 } { 2 } } } ) } ) ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: s _ { \\mathrm { d u a l } } ^ { 2 } = ( N e ^ { \\phi } ) ^ { 2 / ( p - 7 ) } d s _ { \\mathrm { s t r i n g } } ^ { 2 } .\n",
      "Predicted Formula: { { 1 } i e a e } } ^ { 2 } = e _ _ { { 2 } { ^ { 2 } + } + 2 ) } d _ ^ { N { e a a } } e } } ^ { 2 } \\,\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\widehat { n } | \\widehat { n ^ { \\prime } } > = - 2 \\delta _ { n + n ^ { \\prime } } + \\delta _ { n + n ^ { \\prime } + 1 } + \\delta _ { n + n ^ { \\prime } - 1 }\n",
      "Predicted Formula: _ R } ^ { > > } > \\prime } } > > { ^ { ^ { n n } , 1 \\prime } } \\delta { { { 1 ^ ^ } 1 \\prime } } \\delta } \\delta _ { n ^ 1 } { \\prime } } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: L _ { n } , f ] = z ^ { n + 1 } \\partial _ { z } f .\n",
      "Predicted Formula: _ { + } , L _ { { _ { n } 1 } + _ { z } + ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\le k _ { \\mathrm { m i n } } = n _ { \\mathrm { M } } ^ { 1 / 3 }\n",
      "Predicted Formula: { , { 1 } m } } } } \\, k { { \\mathrm { m } } . 2 } 2 } \\ll\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\lambda } ( q ) \\equiv \\sum _ { \\mu \\in W _ { \\lambda } } e ^ { 2 i a \\mu \\cdot q } ,\n",
      "Predicted Formula: { i } ^ { ) = \\sum _ { q = \\lambda \\bf } \\nu } } { _ { - q _ _ } { } .\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\pm } X _ { \\mu } \\psi _ { \\pm } ^ { \\mu , j } = \\partial _ { \\pm } X _ { \\mu } e ^ { j } \\Psi _ { \\pm } ^ { \\mu } = 0 , ~ ~ ~ ~ ~ ~ ~ ~ j = 1 , 2 . . . 6 .\n",
      "Predicted Formula: { + } ^ _ { \\pm } = \\partial { \\mu } ^ { \\mu } = } = 0 , { \\pm } X _ { \\pm } ^ { { \\pm } \\partial _ { \\mp , ^ { \\mu } , \\quad , \\quad \\; ~ ~ ~ ~ ~ ~ ~ ~ { , 2 , 3 . ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { ( i ) } ( x ) = U _ { n } ( \\phi ) \\psi ^ { ( i ) } ( \\rho ) U _ { n } ^ { \\dagger } ( \\phi ) ,\n",
      "Predicted Formula: { a } ) } ( x ) = \\Phi ^ { i } ( x ) x x { ( n ) } ( x ) + { i } ( x ( n ( x )\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { 0 } ^ { > } = - \\frac { 8 k ^ { 2 } } { \\ell _ { 0 } ^ { 2 } } B _ { 1 } ^ { < } , \\quad \\epsilon _ { 2 } ^ { > } = k ^ { 2 } B _ { 2 } ^ { < } - \\frac { 3 w ^ { ( 2 ) > } k ^ { 2 } } { \\ell _ { 0 } ^ { 2 } } B _ { 1 } ^ { < } \\, .\n",
      "Predicted Formula: { \\mu } ^ { 2 } = { _ { \\hbar _ } { 2 } } { 2 ^ { 0 } ^ { 2 } } ^ \\frac { 0 } ^ { 2 } } { \\; < { 2 } ^ { 2 } < _ \\frac { 2 } \\frac \\frac { 2 } ^ { 2 } > _ { 1 ^ } { 2 } ) } - } { { 2 } } { 2 ^ { 0 } ^ { 2 } } . { 0 } ^ { ( } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: Z ^ { M } = \\eta ^ { \\alpha } \\partial _ { \\alpha } Z ^ { M }\n",
      "Predicted Formula: _ \\delta \\underline } = \\partial _ { M } \\partial \\partial { \\alpha } Z ^ M } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: { F } _ { i } ^ { a \\dagger } = - { \\frac { \\partial { W } } { \\partial \\tilde { q } _ { i } ^ { a } } } = - \\sqrt { 2 } \\phi _ { a } ^ { b } q _ { b } ^ { i } - m _ { j } ^ { i } q _ { a } ^ { j } = 0 .\n",
      "Predicted Formula: F } _ { \\mu } } { i } = = { \\frac { { i } } F { { \\partial a _ x } } { i } } } a } } } + { \\frac { \\frac } } \\tilde { i } ^ { i } + _ { i } ^ { i } + \\frac { { i } ^ { i } \\tilde _ { i } ^ { i } { , {\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\frac { 1 } { R _ { S ^ { 3 } } ^ { 2 } } = \\frac { 2 } { | H _ { 0 } | } = e ^ { 2 \\psi _ { 2 } }\n",
      "Predicted Formula: { { 1 } { 2 } { 1 } } 2 } } ^ + 2 } } + \\frac { 1 } } 3 } | ^ \\perp } | } { { 2 _ _ { 0 } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( R ) = V _ { 0 } + \\sigma R + O ( R ^ { - 1 } ) \\\n",
      "Predicted Formula: { ) = R ( { 0 } + R _ { { _ R ^ { - } } )\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { \\prime \\prime } ( u ^ { \\prime \\prime } , v ^ { \\prime \\prime } ) = u ^ { \\frac { 1 } { 2 } ( \\alpha _ { 1 } + \\alpha _ { 3 } - \\alpha _ { 2 } - \\alpha _ { 4 } ) } v ^ { \\frac { 1 } { 2 } ( \\alpha _ { 2 } + \\alpha _ { 3 } - \\alpha _ { 1 } - \\alpha _ { 4 } ) } F ( u , v ) .\n",
      "Predicted Formula: { \\mu } ( ( z _ { \\prime } , , u ) { \\prime } ) ) = \\delta _ { \\prime } 1 } { 2 } } ( ^ { 1 } + u _ { 2 } ) } _ { 2 } ) } _ { 2 } ) } ( ( { \\prime } 1 } { 2 } } ( _ { 1 } - u _ { 2 } ) } _ { 2 } ) } _ { 2 } ) } . ^ { _ { ) {\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\epsilon ^ { i } = \\zeta ^ { i } \\, ; \\qquad \\theta \\zeta ^ { i } = \\epsilon ^ { i } \\, ; \\qquad \\theta \\eta ^ { i } = - \\eta ^ { i } \\, .\n",
      "Predicted Formula: { { i j } \\epsilon , { i } = , \\qquad \\zeta \\epsilon { { i } = \\epsilon \\epsilon { i } } \\epsilon ^ \\epsilon _ { { i } = \\epsilon \\epsilon ^ { i } \\,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\infty } \\left( \\beta \\right) \\simeq \\frac { 1 } { 8 \\sqrt { 3 } } e ^ { 2 \\pi \\beta }\n",
      "Predicted Formula: { \\mathrm } ( \\frac \\right) = \\frac { 1 } { 2 } \\left( \\pi } } } . { - \\beta } / }\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\frac { d ^ { 2 } R } { d y ^ { 2 } } } ~ + ~ ( A + B + \\frac { \\epsilon } { 2 } ) ~ R ~ = ~ 0 ~ .\n",
      "Predicted Formula: { 1 } { 2 } } { { d r ^ { 2 } } } + ( ~ ~ ~ - { ) ^ ) 2 } { 2 } ) ) { ~ { ~ 0 ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mu \\lambda \\rho } \\partial _ { \\lambda } ^ { x } K _ { \\rho \\nu } ( x - y ) \\; = \\; \\delta _ { \\mu \\nu } \\delta ^ { ( 3 ) } ( x - y ) \\; .\n",
      "Predicted Formula: { \\mu } } \\sigma ^ { { \\lambda } F ^ \\mu } } _ { \\lambda } ^ ^ { ^ = ) = \\partial \\; \\epsilon _ { \\nu } ^ ^ { x ( } ) } ( x - y ) ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\cal L } = - \\sum _ { j = 1 } ^ { N } \\left( \\partial ^ { \\nu } \\Psi _ { j } ^ { \\ast } \\partial _ { \\nu } \\Psi _ { j } + m _ { 0 } ^ { 2 } \\Psi _ { j } ^ { \\ast } \\Psi _ { j } - g \\Phi ^ { p } \\left( \\Psi _ { j } ^ { \\ast } \\Psi _ { j } \\right) ^ { q } \\right) - \\frac { 1 } { 2 } \\left( \\partial ^ { \\nu } \\Phi \\partial _ { \\nu } \\Phi + \\mu _ { 0 } ^ { 2 } \\Phi ^ { 2 } \\right)\n",
      "Predicted Formula: L } _ { { { { n = 1 } ^ { n } \\left( _ _ { \\mu } \\partial _ { j } ^ { \\dagger } \\right) _ { j } \\Psi _ { j } ^ { { { j } ^ { 2 } \\Psi \\Psi { j } ^ { \\dagger } \\right) \\Psi { j } ^ { _ { { j } \\right) _ _ { j } ^ { j } \\right) ^ { j } ^ { \\Psi 2 } + \\Psi \\Psi _ 1 } { 2 } \\left( _ _ { j } \\Phi _ { { j } \\Phi ^ { _ { j } ^ { 2 } \\right) \\Psi { j } \\right) \\Psi \\Psi\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\sqrt { \\frac { K } { M _ { \\mathrm { o s c } } } } = \\sqrt { 4 \\pi \\alpha ^ { \\prime } K }\n",
      "Predicted Formula: { { \\frac { 1 } { \\sqrt } { 0 } P r t } } } } d d { 2 { ^ { { 2 } } { {\n",
      "--------------------------------------------------\n",
      "Actual Formula: { \\cal G } _ { 0 } \\right| \\leq { \\frac { 1 } { 5 0 0 } } H _ { 0 } .\n",
      "Predicted Formula: \\right| { } _ { 1 } } { { { G 1 } { 2 } } } } \\, \\cal { 0 } ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { i } = \\omega ^ { - 1 / 2 } [ t n ( \\theta _ { i } / 2 , k ) ] ^ { - 2 / N } , ~ ~ ~ ~ ~ ~ i = 1 , 2 , \\cdots , 6 ,\n",
      "Predicted Formula: { 0 } = { _ { i } } 2 } ( _ _ { { _ { i } ) / _ _ _ { , { - / / = } = \\qquad ~ ~ ~ ~ ~ ~ ~ k , 2 , \\cdots , N _\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( t ) = e ^ { - i \\omega _ { c } ^ { * } t } Q _ { 0 }\n",
      "Predicted Formula: { ) = e ^ { i i _ t } 0 } t } 2 } \\omega } . \\omega } ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { k l } = e _ { k } - e _ { l } , \\, \\, \\, \\, \\, \\, \\, 1 \\le k < l \\le N .\n",
      "Predicted Formula: { 1 } = = \\alpha _ { 1 } + _ _ { l } , , \\; \\, \\, \\, \\, \\, \\, _ e \\le { \\, { . .\n",
      "--------------------------------------------------\n",
      "Actual Formula: d ^ { 4 } x ( - \\frac { 1 } { 2 } G _ { \\mu } G ^ { \\mu } ) = \\frac { 1 } { 4 } \\int d ^ { 4 } x B _ { \\mu \\nu } L ^ { \\mu \\nu \\alpha \\beta } B _ { \\alpha \\beta } ,\n",
      "Predicted Formula: { { 4 } x \\sqrt { { { 1 } { 2 } ) _ { \\mu \\nu } { { \\mu } } = \\frac \\frac 1 } { 2 } \\int _ ^ { 4 } x \\sqrt { { \\mu \\nu ^ ^ ^ { \\mu \\nu } ^ } + \\frac { \\mu \\nu } } {\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { A } = ( x ^ { \\mu } , y ^ { \\alpha \\beta } , \\bar { y } ^ { \\dot { \\alpha } \\dot { \\beta } } ; \\theta ^ { \\alpha } , \\bar { \\theta } ^ { \\dot { \\alpha } } ; v _ { \\alpha } ^ { a } , \\bar { v } _ { \\dot { \\alpha } { } a } )\n",
      "Predicted Formula: { i } { _ ^ ^ { A } , x ^ { \\mu } ) ) A ^ z } ^ { \\mu } \\alpha } } ) \\beta } } ) , ) , 1 } ) , ^ \\theta } ^ { \\dot { \\alpha } } ) _ { { \\dot { ) { \\dot } ) , { \\theta } ^ { \\dot { \\beta } } ^ { { } ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: s ^ { 2 } = d x ^ { 2 } + d y ^ { 2 } + 2 d \\theta d t + ( y d x - x d y ) d \\theta ~ .\n",
      "Predicted Formula: ^ { 2 } = e ^ ^ { 2 } + x x ^ { 2 } + d ^ ^ ^ { + d ^ - { ^ { ^ { ) ^ { ^ { x\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\equiv t _ { 0 } \\leq t _ { 1 } < t _ { 2 } < \\ldots < t _ { p } < t _ { p + 1 } \\equiv ( n + 1 )\n",
      "Predicted Formula: { _ { 1 } ^ { < { 0 } \\leq 1 \\leq { 1 } < < < t _ { 8 } \\leq < _ { 1 } < } \\leq ( _ + 1 ) \\ldots {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { { \\bf C P } ^ { n } } \\omega ^ { n } = n + 1 .\n",
      "Predicted Formula: { 0 } M } _ { { 2 } } d _ { n } { d _ { . .\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { i } \\partial _ { j } \\left( \\varphi - \\psi - \\Gamma \\right) = 0 .\n",
      "Predicted Formula: { \\mu } ( { { i } { = { { \\partial { \\right) { _\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { j } ( x ) = \\sum _ { i } \\alpha _ { j i } u _ { i } ( x ) + \\beta _ { j i } u _ { i } ^ { * } ( x )\n",
      "Predicted Formula: { 0 } } x ) = \\sum _ { j = j _ { i } ^ ^ { { i } ( x ) { _ _ { i j } ( _ { j } } x \\dagger } ( x ) ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\sum _ { s = o d d , n = e v e n } + \\sum _ { s , n = o d d } = \\frac { 2 } { 3 } ( \\sum _ { s , n } - \\sum _ { s , n = e v e n } ) = \\frac { \\pi } { 3 x } .\n",
      "Predicted Formula: \\sum { i = 1 } ^ s s } ^ } = n } s _ \\int { s = { } 0 } ^ } ^ _ \\frac 1 } } 2 } \\sum { _ { s = 1 } = { { { s = { } { } s n } n _ { _ 1 } { 2 } } \\sum\n",
      "--------------------------------------------------\n",
      "Actual Formula: { l } { \\qquad \\left\\{ H _ { \\pm } , H _ { \\pm } \\right\\} = \\pm 4 [ H _ { \\pm } ( \\sigma ) \\pm ( P _ { y } p ) H _ { 0 } ( \\sigma ) + ( \\sigma \\to \\sigma ^ { \\prime } ) ] \\partial _ { \\sigma } \\delta ( \\sigma - \\sigma ^ { \\prime } ) , } \\\\ { \\qquad \\left\\{ H _ { + } , H _ { - } \\right\\} = 4 [ ( P _ { y } p ) H _ { 0 } ( \\sigma ) + ( \\sigma \\to \\sigma ^ { \\prime } ) ] \\partial _ { \\sigma } \\delta ( \\sigma - \\sigma ^ { \\prime } ) , } \\\\ { \\qquad \\left\\{ H _ { 0 } , H _ { \\pm } \\right\\} = \\pm 2 H _ { 0 } ( \\sigma ^ { \\prime } ) \\partial _ { \\sigma } \\delta ( \\sigma - \\sigma ^ { \\prime } ) . } \\\\ \\end{array}\n",
      "Predicted Formula: l l { { _ _ _ { 1 } , { _ { \\pm } \\right\\} = \\pm _ _ { _ { 1 } , H , { H { + { \\pm } \\pm { { Q { \\pm } ] + ) ) P _ + { ) { \\pm } ) ) { { { p } ( , } - p ) , \\prime } ) } \\\\ \\\\ { ( ( ^ { { \\pm } ^ { _ { \\pm } ^ { { } ^ ^ - { \\pm } - { { { { \\pm } ( \\sigma \\sigma { { \\sigma - { ) { \\prime } ) ) } \\\\ { \\sigma } ( \\\\ \\sigma - \\sigma ^ { \\prime } ) } \\\\ \\\\ { \\left[ \\partial & { { \\sigma } ^ { _ { \\sigma } ^ = ( \\sigma \\sigma } { \\sigma } ^ \\sigma \\sigma { - } ) \\sigma } { \\sigma } ( _ { - \\sigma ^ { \\prime } ) } \\\\ \\\\ \\end{array}\n",
      "--------------------------------------------------\n",
      "Actual Formula: ( F ^ { 2 } - \\tilde { G } ^ { 2 } ) = - 8 ( E _ { \\tilde { G } } ^ { 2 } + E _ { F } ^ { 2 } ) .\n",
      "Predicted Formula: = _ = \\prime } ) = ^ F } _ { 2 } ) = { \\frac ^ G ^ { F } Z } } { { 2 } - E { { \\tilde { ^ { 2 } ) ^ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: { \\lbrack m + 1 ] } { P } = \\stackrel { [ i , j , m - i - j + 1 ] } { P ^ { \\prime } } + \\cdots +\n",
      "Predicted Formula: ( 1 , 1 , } { S } { { { ( } ] 1 ] } ] } ] } ] } ] } i ( } { 2 } } m { ( _\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { 1 ^ { \\prime } } = \\alpha V \\, { \\bf \\psi \\cdot r + } \\beta \\, { \\bf p \\cdot \\psi \\, \\, , }\n",
      "Predicted Formula: { + } = \\prime } } = \\psi ^ { { ^ ^ } \\, ^ { ^ { { ^ ^ } ^ { { } \\, {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { H } ^ { ( 2 D ) } = ( 1 + \\epsilon ) { ( 1 - \\epsilon ) } ^ { 1 / 2 } T _ { H } ^ { ( 4 D ) }\n",
      "Predicted Formula: { i } ^ { ( } ) } } = - _ + 2 ) ) { H + 2 ) ) { { ( } 2 } T ( { D } ^ { ( 1 ) } 1 -\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { e n } ^ { P Q } = ( - ) ^ { a } \\sum _ { j = 0 } ^ { a } ( - 1 ) ^ { j } \\left( \\begin{array} { c } { j } \\\\ { a } \\\\ \\end{array} \\right) V _ { * e , n - \\frac { j } { a } } ^ { P Q }\n",
      "Predicted Formula: { \\mathrm } f } { ( } ( = e _ _ ) { n } e _ { n = 1 } ^ { n } e \\frac - ) ^ { j } 1 _ _ c } { a _ \\\\ { a } \\\\ \\end{array} \\right) , { { j } ^ } } = } 1 } { 2 } } } 2 } } }\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { \\mu } ( \\mu = 0 , . . . , 3 ) , \\ \\ \\ A _ { m } ( m = 4 , . . . , D - 1 ) .\n",
      "Predicted Formula: { \\mu } = A , \\nu , = , . , , ) , \\quad \\; _ _ _ { \\mu } = A , = , 1 ) . , m ) { ) .\n",
      "--------------------------------------------------\n",
      "Actual Formula: { T r } ( \\gamma _ { a } ) = 0 ~ , ~ ~ ~ g _ { a } \\not \\in { \\widetilde \\Gamma } ~ .\n",
      "Predicted Formula: ~ r } ( { _ { i } { _ { , \\quad ~ ~ ~ ~ ~ { a } } { 0 _ ~ } _ {\n",
      "--------------------------------------------------\n",
      "Actual Formula: \\eta _ { a } ^ { \\left( 1 \\right) i } = 0 , \\; \\gamma \\eta _ { a } ^ { \\left( 2 \\right) i } = \\partial ^ { i } \\eta _ { a } , \\; \\gamma \\eta _ { a } = 0 ,\n",
      "Predicted Formula: { { a } } { \\dagger } \\right) } } = 0 _ \\quad \\eta \\; { { a } ^ { i } \\right) } = = 0 , { i } \\left( _ { a } ^ 0 \\; 0 { a } ^ { ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { I , q } = J _ { - } ^ { \\prime } J _ { + } ^ { \\prime } + [ J _ { 3 } ^ { \\prime } ] _ { q } [ J _ { 3 } ^ { \\prime } + 1 ] _ { q } ~ ,\n",
      "Predicted Formula: { 1 } = } = A _ { q } } { I I + _ { + } ^ { \\prime } + _ _ _ { + } ^ { \\prime } + J I q } J J , { 1 } ^ J \\prime } + J _ J , q } { ,\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\frac { 1 } { \\pi } \\left( 2 \\alpha ^ { \\prime } \\right) ^ { - d / 2 } \\langle B , y _ { 1 } , v _ { 1 } | D | B , y _ { 2 } , v _ { 2 } \\rangle ~ .\n",
      "Predicted Formula: { \\frac 1 } { 2 } { d { _ { 2 } e ^ { 2 } } 2 } + ^ ^ { \\rangle A 1 } , B , { 2 } , ^ , { { { , { 1 } , . , { 2 } | . {\n",
      "--------------------------------------------------\n",
      "Actual Formula: _ { Q C D } \\sim e ^ { - \\frac { R _ { 1 } } { R _ { 2 } } } / R _ { 1 } .\n",
      "Predicted Formula: { ( } { } = { ^ { - { { 1 } { 0 } } { \\sqrt } { 0 } } } ^ ^ ^ { \\infty } ^\n",
      "--------------------------------------------------\n",
      "Actual Formula: = \\frac { 2 6 } { 3 } \\left\\{ 1 \\pm C \\left( \\frac { 2 2 } { 3 } \\frac { C _ { 2 } ( G ) } { ( 4 \\pi ) ^ { 2 } } g ^ { 2 } \\right) ^ { \\frac { 1 3 } { 2 2 } } \\right\\} ^ { - 1 } .\n",
      "Predicted Formula: { { 1 } } { 3 } \\left( { { \\left( { { { 1 } } { 3 } + ^ 1 } { 1 } } { ) } { 2 _ \\pi ) ^ { 3 } } \\right) ^ { 2 } \\right) ^ { 2 / 1 } { { 2 } } } \\right\\} 1 . 1 / / 2\n",
      "--------------------------------------------------\n",
      "Actual Formula: ^ { + } = \\mathrm { d } z _ { + } ^ { a } \\wedge \\mathrm { d } z _ { - } ^ { a } \\ , \\qquad a = 1 , . . . , n - 3 \\ .\n",
      "Predicted Formula: { + } = _ ^ ~ } a { { 1 } = { \\mathrm } , \\mathrm z d } a { { + } } { - } + \\mathrm \\quad z _ { _ \\dots , . , z _ { ,\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m label_to_index \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(label_to_index_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     59\u001b[0m index_to_label \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m label_to_index\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# Reverse the mapping\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_to_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(val_accuracy)\n\u001b[0;32m     63\u001b[0m save_model(model, optimizer, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, val_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, dataloader, criterion, device, index_to_label)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, formulas \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     13\u001b[0m     images, formulas \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), formulas\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformulas\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass images and input sequence\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), formulas[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m, in \u001b[0;36mImageToLaTeXModel.forward\u001b[1;34m(self, images, formulas)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, formulas):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Encode the images\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: [batch_size, feature_dim]\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Decode to generate the LaTeX expression\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(features, formulas[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Skip the end token\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mEncoderCNN.forward\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[1;32m---> 13\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: [batch_size, feature_dim, 1, 1]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mview(features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten to [batch_size, feature_dim]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(features)\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\resnet.py:158\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m identity\n\u001b[0;32m    161\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bibby\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def decode_formula(indices, index_to_label):\n",
    "    return ' '.join([index_to_label[str(i.item())] for i in indices if i.item() and str(i.item()) != '1'])  # Skip padding\n",
    "\n",
    "\n",
    "def validate_model(model, dataloader, criterion, device, index_to_label):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for images, formulas in dataloader:\n",
    "            images, formulas = images.to(device), formulas.to(device)\n",
    "            outputs = model(images, formulas[:, :-1])  # Pass images and input sequence\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), formulas[:, 1:].contiguous().view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy (if applicable)\n",
    "            predicted_indices = torch.argmax(outputs, dim=2)  # Get the index of the max log-probability\n",
    "            correct_predictions += (predicted_indices == formulas[:, 1:].contiguous()).sum().item()\n",
    "            total_samples += formulas[:, 1:].numel()  # Total number of tokens in the validation batch\n",
    "\n",
    "            # Print images and predictions\n",
    "            for i in range(len(images)):\n",
    "                # Decode the actual and predicted formulas\n",
    "                actual_formula = decode_formula(formulas[i, 1:], index_to_label)  # Skip <S> token\n",
    "                predicted_formula = decode_formula(predicted_indices[i, 1:], index_to_label)  # Skip <S> token\n",
    "                # print(f'Image: {images[i]}')  # This will print the tensor, consider using visualization instead\n",
    "                print(f'Actual Formula: {actual_formula}')\n",
    "                print(f'Predicted Formula: {predicted_formula}')\n",
    "                print('-' * 50)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples if total_samples > 0 else 0.0\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "# Assuming you have your model, dataloader, criterion, and device set up\n",
    "# Assuming 230k.json is loaded as label_to_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = load_model(model, optimizer)\n",
    "\n",
    "val_dataset = LaTeXDataset('LaTex_data/split_1', mapping_path, label_to_index_path, transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)  # Set shuffle to False for validation\n",
    "label_to_index = json.load(open(label_to_index_path, 'r'))\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}  # Reverse the mapping\n",
    "\n",
    "val_loss, val_accuracy = validate_model(model, val_dataloader, criterion, device, index_to_label)\n",
    "print(val_accuracy)\n",
    "save_model(model, optimizer, epoch + 1, val_loss, 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
