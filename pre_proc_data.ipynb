{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class Im2LatexDataset(Dataset):\n",
    "    def __init__(self, data_dir, split, max_len):\n",
    "        \"\"\"args:\n",
    "        data_dir: root dir storing the prepoccessed data\n",
    "        split: train, validate or test\n",
    "        \"\"\"\n",
    "        assert split in [\"train\", \"validate\", \"test\"]\n",
    "        self.data_dir = data_dir\n",
    "        self.split = split\n",
    "        self.max_len = max_len\n",
    "        self.pairs = self._load_pairs()\n",
    "\n",
    "    def _load_pairs(self):\n",
    "        pairs = torch.load(join(self.data_dir, \"{}.pkl\".format(self.split)))\n",
    "        for i, (img, formula) in enumerate(pairs):\n",
    "            pair = (img, \" \".join(formula.split()[:self.max_len]))\n",
    "            pairs[i] = pair\n",
    "        return pairs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.pairs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os.path import join\n",
    "import argparse\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(data_dir, split):\n",
    "\tassert split in [\"train\", \"validate\", \"test\"]\n",
    "\n",
    "\tprint(\"Process {} dataset...\".format(split))\n",
    "\timages_dir = join(data_dir, \"formula_images_processed\")\n",
    "\n",
    "\tsplit_file = join(data_dir, f\"im2latex_{split}.csv\")\n",
    "\tpairs = []\n",
    "\ttransform = transforms.ToTensor()\n",
    "\t\n",
    "\tdf = pd.read_csv(split_file)\n",
    "\n",
    "\tdf = df.dropna(subset=['formula', 'image'])\n",
    "\t\n",
    "\t# Create a dictionary from the DataFrame with 'img_name' as keys and 'formula' as values\n",
    "\tdata = pd.Series(df['formula'].values, index=df['image']).to_dict()\n",
    "\t\n",
    "\tfor k, v in data.items():\n",
    "\t\timg_name, formula = k, v\n",
    "\t\t# load img and its corresponding formula\n",
    "\t\timg_path = join(images_dir, img_name)\n",
    "\t\timg = Image.open(img_path)\n",
    "\t\timg_tensor = transform(img)\n",
    "\t\t# formula = formulas[int(formula_id)]\n",
    "\t\tpair = (img_tensor, formula)\n",
    "\t\tpairs.append(pair)\n",
    "\tpairs.sort(key=img_size)\n",
    "\n",
    "\tout_file = join(data_dir, \"{}.pkl\".format(split))\n",
    "\ttorch.save(pairs, out_file)\n",
    "\tprint(\"Save {} dataset to {}\".format(split, out_file))\n",
    "\n",
    "\n",
    "def img_size(pair):\n",
    "\timg, formula = pair\n",
    "\treturn tuple(img.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process train dataset...\n",
      "Save train dataset to ./100k/train.pkl\n"
     ]
    }
   ],
   "source": [
    "preprocess('./100k/', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process validate dataset...\n",
      "Save validate dataset to ./100k/validate.pkl\n"
     ]
    }
   ],
   "source": [
    "preprocess('./100k/', 'validate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
